{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2c907e",
   "metadata": {
    "id": "eb2c907e"
   },
   "outputs": [],
   "source": [
    "seed = 3906303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ad3916",
   "metadata": {
    "id": "69ad3916"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import r2_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, LabelEncoder\n",
    "\n",
    "import pickle\n",
    "import glob, os\n",
    "import gzip\n",
    "import random\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38e152a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8Q0dcCNGyjJc",
   "metadata": {
    "id": "8Q0dcCNGyjJc"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4WNxIlW8syto",
   "metadata": {
    "id": "4WNxIlW8syto"
   },
   "source": [
    "Here we read in all the measurement files created in the datagen notebook. Each dataframe is a separate file, which is each a separate table of measurement readings of particular types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fvVZ1hJdg8s1",
   "metadata": {
    "id": "fvVZ1hJdg8s1"
   },
   "outputs": [],
   "source": [
    "# Create dictionary of measurement-type dataframes\n",
    "MEAS = {\n",
    "    name: pd.read_csv(\n",
    "        fp,\n",
    "        parse_dates=['charttime'],       # parsed dates on the fly\n",
    "        low_memory=False                 # avoids mixed-type warnings\n",
    "    )\n",
    "    for fp  in sorted(glob.glob('Datagen/*_filtered_chartevents.csv'))\n",
    "    for name in [os.path.basename(fp).split('_')[0]]\n",
    "}\n",
    "\n",
    "FEATURES = list(MEAS.keys())\n",
    "F        = len(FEATURES)             # number of features\n",
    "GLU_IDX  = FEATURES.index('bg')     # which column contains glucose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6HaTFPFvJ4M",
   "metadata": {
    "id": "f6HaTFPFvJ4M"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abpm', 'bg', 'cvp', 'f', 'hr', 'hrh', 'hrl', 'nbpm', 'rr', 'spo2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YwrUFnBPe0r_",
   "metadata": {
    "id": "YwrUFnBPe0r_"
   },
   "source": [
    "# Data filtering and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pBaoX7aRuqyO",
   "metadata": {
    "id": "pBaoX7aRuqyO"
   },
   "source": [
    "Below we filter impossible values for the physiological features. No negative numbers, except for rare cases of CVP feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "KRz4MR5FQcZu",
   "metadata": {
    "id": "KRz4MR5FQcZu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abpm: 61408 invalid rows\n",
      "bg: 351 invalid rows\n",
      "cvp: 73743 invalid rows\n",
      "f: 1052 invalid rows\n",
      "hr: 3926 invalid rows\n",
      "hrh: 5461 invalid rows\n",
      "hrl: 3986 invalid rows\n",
      "nbpm: 98189 invalid rows\n",
      "rr: 43720 invalid rows\n",
      "spo2: 3251 invalid rows\n"
     ]
    }
   ],
   "source": [
    "#  Per-variable rules. Only reject impossible numbers\n",
    "LOGIC_RULES = {\n",
    "    'bg' : lambda s: (s >= 10) & (s <= 2656),                     # historically recorded extreme mg/dL\n",
    "    'hr'  : lambda s: (s >= 20) & (s <= 600),                     # beats / min\n",
    "    'rr'  : lambda s: (s >= 6) & (s <= 60),                       # breaths / min\n",
    "    'spo2': lambda s: (s >= 50) & (s <= 100),                     # % saturation\n",
    "    'nbpm': lambda s: (s >= 50) & (s <= 130),                     # mm Hg\n",
    "    'abpm': lambda s: (s >= 50) & (s <= 130),                     # mm Hg\n",
    "    'f'   : lambda s: (s >= 53) & (s <= 116),                     # F < 0 impossible\n",
    "    # CVP can dip a few mm Hg negative during inspiration\n",
    "    'cvp' : lambda s: (s >= -5) & (s <= 20),                      # allow mild physio negative\n",
    "    'hrl' : lambda s: (s >= 30) & (s <= 100),\n",
    "    'hrh' : lambda s: (s >= 100) & (s <= 600),\n",
    "}\n",
    "\n",
    "def filter_impossible(df, short_name):\n",
    "    df = df.copy()\n",
    "    rule = LOGIC_RULES.get(short_name)\n",
    "    if rule is None:\n",
    "        raise KeyError(f\"No logic rule defined for '{short_name}'\")\n",
    "    return df[rule(df['value'])]\n",
    "\n",
    "# Apply to every dataframe in the MEAS dict\n",
    "MEAS_CLEAN = {\n",
    "    name: filter_impossible(df, name)\n",
    "    for name, df in MEAS.items()\n",
    "}\n",
    "\n",
    "# Invert logic rules to capture invalid (impossible) values\n",
    "def get_invalid(df, short_name):\n",
    "    df = df.copy()\n",
    "    rule = LOGIC_RULES.get(short_name)\n",
    "    if rule is None:\n",
    "        raise KeyError(f\"No logic rule defined for '{short_name}'\")\n",
    "    return df[~rule(df['value'])]  # Invert the logic to get invalids\n",
    "\n",
    "# Store invalid rows per measurement\n",
    "MEAS_INVALID = {\n",
    "    name: get_invalid(df, name)\n",
    "    for name, df in MEAS.items()\n",
    "}\n",
    "\n",
    "# Print counts of invalid entries\n",
    "for name, df in MEAS_INVALID.items():\n",
    "    print(f\"{name}: {len(df)} invalid rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508b32d",
   "metadata": {},
   "source": [
    "## Valid data range sources:\n",
    "- Blood Glucose: 10-2656 mg/dL https://casereports.bmj.com/content/15/7/e245890 (min recorded)\n",
    "- Heartrate: 20–600 bpm https://en.wikipedia.org/wiki/Heart_rate (max recorded)\n",
    "- Respiratory Rate: 6–60 breaths per minute https://en.wikipedia.org/wiki/Respiratory_rate\n",
    "- Oxygen Saturation: 50–100% https://www.verywellhealth.com/blood-oxygen-level-8656297\n",
    "- Non-Invasive Blood Pressure Mean: 50–130 mmHg https://www.healthline.com/health/mean-arterial-pressure#high-map\n",
    "- Arterial Blood Pressure Mean: 50–130 mmHg https://www.healthline.com/health/mean-arterial-pressure#high-map\n",
    "- Temperature Fahrenheit: 53–116°F https://en.wikipedia.org/wiki/Human_body_temperature (lowest recorded)\n",
    "- Central Venous Pressure: -5 to 20 mmHg (lost source)\n",
    "- Heart Rate Alarm Low: 30–100 bpm https://www.verywellhealth.com/dangerous-heart-rate-5215509\n",
    "- Heart Rate Alarm High: 100–600 bpm https://en.wikipedia.org/wiki/Heart_rate (same as above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3b772",
   "metadata": {
    "id": "f4b3b772"
   },
   "source": [
    "# Split Dataset into Training, Validation and Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "OZjtGiJgoJMd",
   "metadata": {
    "id": "OZjtGiJgoJMd"
   },
   "outputs": [],
   "source": [
    "unique_subjects = MEAS_CLEAN['bg']['subject_id'].unique()\n",
    "train_subjects, test_subjects = train_test_split(unique_subjects, test_size=0.2,\n",
    "                                         random_state=seed)\n",
    "train_subjects, val_subjects  = train_test_split(train_subjects, test_size=0.25,\n",
    "                                         random_state=seed)\n",
    "\n",
    "SPLIT = {'train': train_subjects, 'val': val_subjects, 'test': test_subjects}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44544a7",
   "metadata": {},
   "source": [
    "## ICU stay length EDA\n",
    "\n",
    "Here we explore the distribution of ICU stay lengths, visualise them in histograms and box plots, to get a good idea of the horizon lengths of ICU stays we should consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ab94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = MEAS_CLEAN['bg'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae4bb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = bg.groupby('stay_id')['charttime'].apply(lambda x: x.max() - x.min())\n",
    "time_diffs_hours = time_diffs.dt.total_seconds() / 3600  # convert to hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51414513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stay_id\n",
       "36032605   224 days 17:39:00\n",
       "39510663   165 days 07:28:00\n",
       "37583392   164 days 21:38:00\n",
       "34776085   160 days 23:58:00\n",
       "36307509   159 days 08:37:00\n",
       "                  ...       \n",
       "30626722     0 days 00:00:00\n",
       "35019413     0 days 00:00:00\n",
       "35017950     0 days 00:00:00\n",
       "30625722     0 days 00:00:00\n",
       "38519882     0 days 00:00:00\n",
       "Name: charttime, Length: 92299, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_diffs.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b510798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(time_diffs_hours, bins=50, kde=True)\n",
    "plt.xlabel(\"Duration of ICU Stay (hours)\")\n",
    "plt.ylabel(\"Number of ICU stays\")\n",
    "plt.title(\"Distribution of Time Ranges Within Each Stay (before filtering outliers)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86cf6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove only higher outliers using IQR rule. The code in cells below can handle single value ICU stays.\n",
    "filtered_diffs = time_diffs_hours[\n",
    "    (time_diffs_hours <= time_diffs_hours.quantile(0.75) + \n",
    "     1.5 * (time_diffs_hours.quantile(0.75) - time_diffs_hours.quantile(0.25)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e52d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(filtered_diffs, bins=50, kde=True)\n",
    "plt.xlabel(\"Duration of ICU Stay (hours)\")\n",
    "plt.ylabel(\"Number of ICU stays\")\n",
    "plt.title(\"Distribution of Time Ranges Within Each Stay (Outliers Removed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a758bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyQAAADtCAYAAABOBbHlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0i0lEQVR4nO3de3zP9f//8ft79t7eb9vMeQeHzZxj5lRCsQiR7JNjSA4lRajIoV8OURE6fXKs2FLCxyeWz+RUplSUcigsfMoppiJD2Ozw/P3Rd++Pd5udzF5Nt+vlsovt+To9Xs8997q87u/Xgc0YYwQAAAAAFvCwugAAAAAAf18EEgAAAACWIZAAAAAAsAyBBAAAAIBlCCQAAAAALEMgAQAAAGAZAgkAAAAAyxBIAAAAAFiGQAIAAADAMgQS4AYTExMjm82mr7/+Osu0LVu2qGfPnqpUqZK8vLzk7++vFi1aaN68ebpw4YJrPpvNpsceeyzb9f/73/+WzWbT5s2bc63lyy+/1L333quqVavK29tbAQEBat68uUaNGuU239y5cxUTE5Ov/SxMkZGRstlsstls8vDwkJ+fn2rUqKEePXro3//+tzIyMiyrTZL27dunyZMn6/Dhw1mmDRgwQKGhoUVeU6YffvhB3t7e2rp1q1u7MUbvvfee2rRpozJlysjb21thYWEaNmyYjh07VuDtnThxQpMnT9auXbuyTJs8ebJsNptbW2RkpCIjIwu8vcIWGhrqGms2m00+Pj5q3LixZs+eLWOM1eX9JWQew64c761atdLjjz9uWU0Ari8CCfA3MWnSJLVq1UrHjx/X1KlTtXHjRi1btkxt27bV5MmT9cwzzxTq9tasWaMWLVro3LlzmjFjhjZs2KDXXntNLVu21PLly93mtTqQSFJYWJi2bt2qL774QrGxsRo3bpwuXbqkHj16KDIyUmfPnrWstn379unZZ5/NNpBMmDBBq1atKvqi/s/o0aPVrl07NW/e3NWWkZGh3r17q2/fvgoMDFRMTIzWr1+vxx9/XKtXr1aDBg30+eefF2h7J06c0LPPPpttIMnO3LlzNXfu3AJt63pp2bKltm7dqq1bt+qdd95RyZIlNXz4cE2bNs3q0v6ypk6dqrlz52r//v1WlwLgOvC0ugAA19+KFSs0ZcoUPfjgg3rzzTfdPkXu2LGjxowZk+UT7ms1Y8YMVatWTevXr5en5/8ONffdd59mzJhRqNsqDE6nU7feeqtb20MPPaTo6GgNGjRIDz/8cJYgVVAXL15UyZIlC2Vd1atXL5T1FERCQoJiY2O1bt06t/YXX3xRy5cv1/Tp0zV27FhXe2RkpHr16qVmzZqpW7du+v7771W6dOnrWuNNN91UqOu7dOmSnE7nNa2jdOnSbmPtzjvvVNWqVbVgwQI9/fTT11riDal169aqXbu2XnrpJb3xxhtWlwOgkHGFBPgbmDJlisqUKaN//vOfWW5pkSQ/Pz+1b9++ULd5+vRplS9f3i2MZPLw+N+hJzQ0VHv37tUnn3ziuo0l8xak5ORkjRo1Sg0bNpS/v7/Kli2r5s2b64MPPnBbX9u2bVWnTp0st7wYY1SjRg3dfffdBd6PgQMHqlOnTlqxYoWOHDkiSTp8+LBsNlu2V3VsNpsmT57s+jnzNqIdO3aoe/fuKlOmjCtEfP3117rvvvsUGhoqp9Op0NBQ9e7d27Ud6Y/bV3r06CFJuuOOO1x9lLnt7G7ZSk5O1vjx41WtWjV5eXmpUqVKGjZsmJKSktzmCw0NVefOnbVu3To1btxYTqdTderU0aJFi/LUN/PmzVNgYKDatWvnart8+bJmzpypunXrasyYMVmWCQgI0LRp0/Tzzz9r4cKFbrUMGDAgy/xX3nK1efNm3XzzzZL++L1k9sWV/Z3T8lfW+Nxzz6lOnTry9vZWhQoVNHDgQP36669u82X2z8qVK9WoUSM5HA49++yzkv4I+c2aNZO/v79KliypsLAwDRo0KKfuuqpSpUqpVq1a+vnnn6+pzri4ODVq1EhOp1N169ZVXFycpD/GUN26deXj46Nbbrkl29s5V69erebNm6tkyZLy8/NTu3bt3D6kiI2Nlc1m08cff5xl2Xnz5slms+nbb791tX399dfq0qWLypYtK4fDoUaNGulf//pXlmW3bdumli1byuFwKDg4WOPHj1dqamq2/dSvXz+99957On/+fA69CaA4IpAAN7jExETt2bNH7du3L7RP5fOiefPm+vLLLzVixAh9+eWXVz3JWLVqlcLCwtSoUSPXbSyZtyClpKTot99+0+jRoxUbG6ulS5fqtttuU9euXbV48WLXOkaOHKn9+/dnOVlau3atfvjhBw0bNuya9qVLly4yxmjLli0FXkfXrl1Vo0YNrVixQvPnz5f0R7CpXbu2Xn31Va1fv14vvviiEhMTdfPNN+vUqVOSpLvvvlsvvPCCJGnOnDmuPrpayDLG6B//+IdmzZqlfv36ac2aNXryySf19ttvq02bNkpJSXGbf/fu3Ro1apSeeOIJffDBB2rQoIEefPBBffrpp7nu05o1a9SqVSu3gPnNN9/ozJkz6tKlS7bhV5LuueceeXh4aOPGjbl33BUaN26s6OhoSdIzzzzj6ouHHnooz+vIyMhQVFSUpk+frj59+mjNmjWaPn26Nm7cqMjISF26dMlt/h07duipp57SiBEjtG7dOnXr1k1bt25Vr169FBYWpmXLlmnNmjWaOHGi0tLS8rU/mdLS0nTs2DHVqlWrwHXu3r1b48eP19ixY7Vy5Ur5+/ura9eumjRpkt566y298MILWrJkic6ePavOnTu7Lf/ee+8pKipKpUqV0tKlS7Vw4UKdOXNGkZGR+uyzzyRJnTt3VsWKFV39f6WYmBg1btxYDRo0kCTFx8erZcuWSkpK0vz58/XBBx+oYcOG6tWrl1uI37dvn9q2baukpCTFxMRo/vz52rlzp5577rls+ykyMlIXLlzI0/NrAIoZA+CGEh0dbSSZ7du3G2OM2bZtm5Fkxo0bl+d1SDLDhg3LdtqKFSuMJBMfH5/jOk6dOmVuu+02I8lIMna73bRo0cJMmzbNnD9/3m3eevXqmdatW+daV1pamklNTTUPPvigadSokas9PT3dhIWFmaioKLf5O3bsaKpXr24yMjJyXG/r1q1NvXr1rjp97dq1RpJ58cUXjTHGHDp0yEgy0dHRWeaVZCZNmuT6edKkSUaSmThxYp727/fffzc+Pj7mtddec7Xn1Of9+/c3ISEhrp/XrVtnJJkZM2a4zbd8+XIjybzxxhuutpCQEONwOMyRI0dcbZcuXTJly5Y1Q4YMybHWn3/+2Ugy06dPd2tftmyZkWTmz5+f4/IBAQGmbt26brX0798/y3ytW7d2Gxvbt2+/at9n9nVOyy9dutRIMu+//77bfJnrnTt3rltNJUqUMPv373ebd9asWUaSSUpKynEfsxMSEmI6depkUlNTTWpqqjly5IgZPHiwsdvtJi4ursB1Op1O89NPP7nadu3aZSSZoKAgc+HCBVd7bGyskWRWr15tjPnjbyc4ONiEh4eb9PR013znz583FStWNC1atHC1Pfnkk8bpdLrt9759+4wk8/rrr7va6tSpYxo1amRSU1Pdau/cubMJCgpybadXr17G6XSakydPuuZJS0szderUMZLMoUOH3Ja/fPmysdlsZuzYsTn0MIDiiCskAK6LcuXKacuWLdq+fbumT5+uqKgoHThwQOPHj1d4eLjrCkBuVqxYoZYtW8rX11eenp6y2+1auHChEhISXPN4eHjoscceU1xcnI4ePSrpj7c/rVu3TkOHDr3qJ/V5ZQrh7UfdunXL0vb7779r7NixqlGjhjw9PeXp6SlfX19duHDBbf/yY9OmTZKU5fanHj16yMfHJ8tVpIYNG6pq1aqunx0Oh2rVquV221h2Tpw4IUmqWLFigeo0xlzz76Ug4uLiVLp0ad1zzz1KS0tzfTVs2FCBgYFZPn1v0KCB25ULSa7bxnr27Kl//etfOn78eL5q+PDDD2W322W32xUSEqI333xTr7/+uttVr/zW2bBhQ1WqVMn1c926dSX9cVXhyiujme2Zv9/9+/frxIkT6tevn9uVLl9fX3Xr1k3btm3TxYsXJUmDBg3SpUuX3J6lio6Olre3t/r06SNJ+u9//6vvv/9effv2lSS32jt16qTExETXg+nx8fFq27atAgICXOsrUaKEevXqlW2/2e12lS5dOt/9DeCvj0AC3OAyTzYPHTqU52VKlCih9PT0bKdl3pZit9vztK6mTZtq7NixWrFihU6cOKEnnnhChw8fztOD7StXrnS9pvjdd9/V1q1btX37dg0aNEjJyclu8w4aNEhOp9N1O9ScOXPkdDoLfF//lTJP3oKDgwu8jqCgoCxtffr00ezZs/XQQw9p/fr1+uqrr7R9+3ZVqFAhyy05eXX69Gl5enqqQoUKbu02m02BgYE6ffq0W3u5cuWyrMPb2zvX7WdOdzgcbu15GW8XLlzQqVOnVKVKlRy3cT38/PPPSkpKkpeXlysUZH6dPHkyS1DO7vfWqlUrxcbGKi0tTQ888IAqV66s+vXra+nSpXmq4bbbbtP27du1bds2vfPOOwoNDdVjjz3muj2qIHWWLVvW7WcvL68c2zP/fjLHQ3b7GRwcrIyMDJ05c0aSVK9ePd18882u27bS09P17rvvKioqyrWdzOdgRo8enaXuoUOHSpKr9tOnTyswMDDLdrNry+RwOAr8twHgr4u3bAE3uKCgIIWHh2vDhg15frtTQEDAVT+FzGy/8lPNvLLb7Zo0aZJeeeUV7dmzJ9f53333XVWrVk3Lly93+zT9z89BSJK/v7/69++vt956S6NHj1Z0dLT69OlTKG9xWr16tWw2m1q1aiXpfyfhf67jzyf7V/rz1YCzZ88qLi5OkyZN0rhx41ztmc/NFFS5cuWUlpamX3/91S2UGGN08uRJ16f716p8+fKSlKXWJk2aqEyZMlq9erWmTZuW7VWQ1atXKyMjw+1heIfDke3v9dSpU65tFVbd5cqVy/JmsEx+fn5uP1/tKk5UVJSioqKUkpKibdu2adq0aerTp49CQ0PdXoGcHX9/fzVt2lSS1KxZMzVr1kwREREaOnSodu3aJQ8Pj3zXWVCZgTQxMTHLtBMnTsjDw0NlypRxtQ0cOFBDhw5VQkKCfvzxRyUmJmrgwIGu6Zm/q/Hjx6tr167ZbrN27dqubZ88eTLL9OzaMp05c6ZQxwOAvwaukAB/AxMmTNCZM2c0YsSIbG8/+v3337VhwwbXz3feeafi4+OzvM3HGKMVK1YoNDRUNWrUyHGb2Z3gSHLdinTl1YarfSJvs9nk5eXldlJ48uTJLG/ZyjRixAidOnVK3bt3V1JS0lX/c8f8iI6O1tq1a9W7d2/Xp/8BAQFyOBxubxWSdNW6smOz2WSMkbe3t1v7W2+9leXqVOY8eflkuG3btpL+CHNXev/993XhwgXX9GsVEhIip9OpH374wa3dy8tLTz31lBISEjRz5swsy/3yyy8aP368AgIC3B5GDw0NzdKfBw4cyPL/TuSnL7LTuXNnnT59Wunp6WratGmWr8yT5bzy9vZW69at9eKLL0qSdu7cme+aatasqTFjxui7775z3Q5V2HVeTe3atVWpUiW99957bseGCxcu6P3333e9eStT79695XA4FBMTo5iYGFWqVMntDX21a9dWzZo1tXv37mzrbtq0qStM3XHHHfr444/d3i6Wnp5+1ddrnzhxQsnJyYX+KmcA1uMKCfA30KNHD02YMEFTp07V999/rwcffFDVq1fXxYsX9eWXX2rBggXq1auX68Ri4sSJ+s9//qNmzZpp3Lhxqlmzpk6ePKk333xT27dvz/b1nX/WoUMHVa5cWffcc4/q1KmjjIwM7dq1Sy+99JJ8fX01cuRI17zh4eFatmyZli9frrCwMDkcDoWHh7teuTp06FB1795dx44d09SpUxUUFKSDBw9m2WatWrV01113ae3atbrtttsUERGR5z66dOmStm3b5vr+xx9/VGxsrOLi4tS6dWvXrWDSH2Hi/vvv16JFi1S9enVFREToq6++0nvvvZfn7ZUqVUqtWrXSzJkzVb58eYWGhuqTTz7RwoULs1zVqV+/viTpjTfekJ+fnxwOh6pVq5bt7Vbt2rVThw4dNHbsWJ07d04tW7bUt99+q0mTJqlRo0bq169fnmvMiZeXl5o3b+7qsyuNHTtWu3fvdv3bq1cv+fv769tvv9XMmTN1/vx5xcXFyd/f37VMv379dP/992vo0KHq1q2bjhw5ohkzZmS59ax69epyOp1asmSJ6tatK19fXwUHB+f5drr77rtPS5YsUadOnTRy5Ejdcsststvt+umnnxQfH6+oqCjde++9Oa5j4sSJ+umnn9S2bVtVrlxZSUlJeu2112S329W6des81fFno0eP1vz58/Xss8+qZ8+ehVJnXnh4eGjGjBnq27evOnfurCFDhiglJUUzZ85UUlKSpk+f7jZ/6dKlde+99yomJkZJSUkaPXq027MnkrRgwQJ17NhRHTp00IABA1SpUiX99ttvSkhI0I4dO7RixQpJf7wpbfXq1WrTpo0mTpyokiVLas6cObpw4UK2tWaOtTvuuOOa9xvAX4yFD9QDuA7+/JatK33yySeme/fuJigoyNjtdlOqVCnTvHlzM3PmTHPu3Dm3eQ8ePGjuv/9+ExQUZDw9PU3p0qVN+/btzccff5ynOpYvX2769OljatasaXx9fY3dbjdVq1Y1/fr1M/v27XOb9/Dhw6Z9+/bGz8/PSHJ7a9T06dNNaGio8fb2NnXr1jVvvvlmtm9TyhQTE2MkmWXLluWpTmP+eBOT/u9tYJKMj4+PCQsLM927dzcrVqxwe/tQprNnz5qHHnrIBAQEGB8fH3PPPfeYw4cPX/UtW7/++muWdfz000+mW7dupkyZMsbPz8/cddddZs+ePdm+cerVV1811apVMyVKlHB7y9Sf37JlzB9vyho7dqwJCQkxdrvdBAUFmUcffdScOXPGbb6QkBBz9913Z9sfeXnr2cKFC02JEiXMiRMnskzLyMgwS5YsMZGRkaZ06dLGy8vLVKtWzTz66KNub/W6cv4ZM2aYsLAw43A4TNOmTc2mTZuyrWXp0qWmTp06xm63u/V3Xt6yZYwxqampZtasWSYiIsI4HA7j6+tr6tSpY4YMGWIOHjyYa//ExcWZjh07mkqVKhkvLy9TsWJF06lTJ7Nly5Zc++xq6zTGmDlz5hhJ5u233y6UOpXN2/Iy3xA3c+ZMt/bY2FjTrFkz43A4jI+Pj2nbtq35/PPPs61zw4YNrr+VAwcOZDvP7t27Tc+ePU3FihWN3W43gYGBpk2bNlnevvb555+bW2+91Xh7e5vAwEDz1FNPmTfeeCPbt2z169fPhIeHZ7s9AMWbzZhCeH0MAPxFZL4Z6PDhw3l+8B4Fk5ycrKpVq2rUqFFu/yM7UNjOnTun4OBgvfLKKxo8eLDV5QAoZDxDAqDYS0lJ0datW/Xaa69p1apVeuqppwgjRSDzfy5/+eWXr3qbDVAYXnnlFVWtWtXtAXoANw6eIQFQ7CUmJqpFixYqVaqUhgwZouHDh1td0t/Gww8/rKSkJP34448KDw+3uhzcoEqVKqWYmBh5enLaAtyIuGULAAAAgGW4ZQsAAACAZQgkAAAAACxDIAEAAABgmQI/HZaRkaETJ07Iz8/P7X9RBgAAAPD3YozR+fPnFRwcnOU/TM1NgQPJiRMnVKVKlYIuDgAAAOAGc+zYMVWuXDlfyxQ4kPj5+bk2WqpUqYKuBgAAAEAxd+7cOVWpUsWVEfKjwIEk8zatUqVKEUgAAAAAFOhRDh5qBwAAAGAZAgkAAAAAyxBIAAAAAFiGQAIAAADAMgQSAAAAAJYhkAAAAACwDIEEAAAAgGUIJAAAAAAsQyABAAAAYBkCCQAAAADLeFpdAPLOGKPk5GSry7CMMUYpKSmSJG9vb9lsNosrQlFyOBz8zgEAuAERSIqR5ORkdezY0eoyAEusXbtWTqfT6jIAAEAh45YtAAAAAJbhCkkx9XvD3jIef7NfX3qq/HYvkySdj7hPKmG3uCBcb7aMNPnuWmp1GQAA4Dr6m53R3jiMh+ff+4S8hP3vvf9/E8bqAgAAwHXHLVsAAAAALEMgAQAAAGAZAgkAAAAAyxBIAAAAAFiGQAIAAADAMgQSAAAAAJYhkAAAAACwDIEEAAAAgGUIJAAAAAAsQyABAAAAYBkCCQAAAADLEEgAAAAAWIZAAgAAAMAyBBIAAAAAliGQAAAAALAMgQQAAACAZQgkAAAAACxDIAEAAABgGQIJAAAAAMsQSAAAAABYhkACAAAAwDIEEgAAAACWIZAAAAAAsAyBBAAAAIBlCCQAAAAALEMgAQAAAGAZT6sLuFbGGCUnJ0uSHA6HbDabxRUBAIDihvMJwDrF/gpJcnKyOnbsqI4dO7oOJAAAAPnB+QRgnWIfSAAAAAAUXwQSAAAAAJYhkAAAAACwDIEEAAAAgGUIJAAAAAAsQyABAAAAYBkCCQAAAADLEEgAAAAAWIZAAgAAAMAyBBIAAAAAliGQAAAAALAMgQQAAACAZQgkAAAAACxDIAEAAABgGQIJAAAAAMsQSAAAAABYhkACAAAAwDIEEgAAAACWIZAAAAAAsAyBBAAAAIBlCCQAAAAALEMgAQAAAGAZAgkAAAAAyxBIAAAAAFiGQAIAAADAMgQSAAAAAJbxtLoAAACAv5KOHTtaXQKQL1WrVtXixYutLqPAuEICAAD+9s6ePWt1CUCBHT16VAcPHrS6jAIjkAAAgL+9qVOnWl0CcE0effRRq0sosGJ/y5YxxvV9cnKyhZVcf277d8V+Azesv9HfNwDr7Ny5U3v37rW6DOCapKWlaf78+XrkkUesLiXf8hxIUlJSlJKS4vr53Llz16Wg/LqypnvvvdfCSopYRpokL6urAK6vjDTXt3+rv28AAApg2bJlevDBB2W3260uJV/yfMvWtGnT5O/v7/qqUqXK9awLAAAAQD69/vrrVpeQb3m+QjJ+/Hg9+eSTrp/PnTv3lwgl3t7eru9XrVolh8NhYTXXV3Jy8v8+JfYo9nfbAbm7Ypzf6H/fAKyRkZGhu+++2+oygEIzfPhwq0vItzyf1Xp7e7ud/P9V2Gw21/cOh0NOp9PCaorQFfsN3LD+rn/fAIrUrFmzNHr0aKvLAK5Znz59it3tWhJv2QIAAH9zTZs2Vb169awuA7gmnp6eevjhh60uo0AIJAAA4G9vwoQJVpcAXJN58+ZZXUKBEUgAAMDfnr+/v9UlAAVWtWpV1axZ0+oyCownowEAAK6wdu1anlkDihBXSAAAAABYhkACAAAAwDIEEgAAAACWIZAAAAAAsAyBBAAAAIBlCCQAAAAALEMgAQAAAGAZAgkAAAAAyxBIAAAAAFiGQAIAAADAMgQSAAAAAJYhkAAAAACwDIEEAAAAgGUIJAAAAAAsQyABAAAAYBkCCQAAAADLEEgAAAAAWIZAAgAAAMAyBBIAAAAAliGQAAAAALAMgQQAAACAZQgkAAAAACxDIAEAAABgGQIJAAAAAMsQSAAAAABYxtPqAq6Vw+HQ2rVrXd8DAADkF+cTgHWKfSCx2WxyOp1WlwEAAIoxzicA63DLFgAAAADLEEgAAAAAWIZAAgAAAMAyBBIAAAAAliGQAAAAALAMgQQAAACAZQgkAAAAACxDIAEAAABgGQIJAAAAAMsQSAAAAABYhkACAAAAwDIEEgAAAACWIZAAAAAAsAyBBAAAAIBlCCQAAAAALEMgAQAAAGAZAgkAAAAAyxBIAAAAAFiGQAIAAADAMgQSAAAAAJYhkAAAAACwDIEEAAAAgGUIJAAAAAAsQyABAAAAYBkCCQAAAADLeFpdAArGlpEmY3URRS09NfvvccOyZaRZXQIAALjOCCTFlO+upVaXYCm/3cusLgEAAACFgFu2AAAAAFiGKyTFiMPh0Nq1a60uwzLGGKWkpEiSvL29ZbPZLK4IRcnhcFhdAgAAuA4IJMWIzWaT0+m0ugxLlSxZ0uoSAAAAUIi4ZQsAAACAZQgkAAAAACxDIAEAAABgGQIJAAAAAMsQSAAAAABYhkACAAAAwDIEEgAAAACWIZAAAAAAsAyBBAAAAIBlCCQAAAAALEMgAQAAAGAZAgkAAAAAy3gWdEFjjCTp3LlzhVYMAAAAgOInMxNkZoT8KHAgOX/+vCSpSpUqBV0FAAAAgBvI+fPn5e/vn69lbKYgMUZSRkaGTpw4IT8/P9lstoKsotCcO3dOVapU0bFjx1SqVClLa7nR0ddFi/4uOvR10aK/iw59XbTo76JDXxedvPS1MUbnz59XcHCwPDzy91RIga+QeHh4qHLlygVd/LooVaoUA7KI0NdFi/4uOvR10aK/iw59XbTo76JDXxed3Po6v1dGMvFQOwAAAADLEEgAAAAAWOaGCCTe3t6aNGmSvL29rS7lhkdfFy36u+jQ10WL/i469HXRor+LDn1ddK53Xxf4oXYAAAAAuFY3xBUSAAAAAMUTgQQAAACAZQgkAAAAACxDIAEAAABgmRsikMydO1fVqlWTw+FQkyZNtGXLFqtLKvamTZumm2++WX5+fqpYsaL+8Y9/aP/+/W7zDBgwQDabze3r1ltvtaji4mvy5MlZ+jEwMNA13RijyZMnKzg4WE6nU5GRkdq7d6+FFRdvoaGhWfrbZrNp2LBhkhjX1+LTTz/VPffco+DgYNlsNsXGxrpNz8tYTklJ0fDhw1W+fHn5+PioS5cu+umnn4pwL4qHnPo6NTVVY8eOVXh4uHx8fBQcHKwHHnhAJ06ccFtHZGRklrF+3333FfGeFA+5je28HDcY23mTW19nd/y22WyaOXOmax7Gdt7k5VyvqI7bxT6QLF++XI8//rj+3//7f9q5c6duv/12dezYUUePHrW6tGLtk08+0bBhw7Rt2zZt3LhRaWlpat++vS5cuOA231133aXExETX14cffmhRxcVbvXr13Prxu+++c02bMWOGXn75Zc2ePVvbt29XYGCg2rVrp/Pnz1tYcfG1fft2t77euHGjJKlHjx6ueRjXBXPhwgVFRERo9uzZ2U7Py1h+/PHHtWrVKi1btkyfffaZfv/9d3Xu3Fnp6elFtRvFQk59ffHiRe3YsUMTJkzQjh07tHLlSh04cEBdunTJMu/gwYPdxvqCBQuKovxiJ7exLeV+3GBs501ufX1lHycmJmrRokWy2Wzq1q2b23yM7dzl5VyvyI7bppi75ZZbzCOPPOLWVqdOHTNu3DiLKrox/fLLL0aS+eSTT1xt/fv3N1FRUdYVdYOYNGmSiYiIyHZaRkaGCQwMNNOnT3e1JScnG39/fzN//vwiqvDGNnLkSFO9enWTkZFhjGFcFxZJZtWqVa6f8zKWk5KSjN1uN8uWLXPNc/z4cePh4WHWrVtXZLUXN3/u6+x89dVXRpI5cuSIq61169Zm5MiR17e4G1B2/Z3bcYOxXTB5GdtRUVGmTZs2bm2M7YL587leUR63i/UVksuXL+ubb75R+/bt3drbt2+vL774wqKqbkxnz56VJJUtW9atffPmzapYsaJq1aqlwYMH65dffrGivGLv4MGDCg4OVrVq1XTffffpxx9/lCQdOnRIJ0+edBvj3t7eat26NWO8EFy+fFnvvvuuBg0aJJvN5mpnXBe+vIzlb775RqmpqW7zBAcHq379+oz3a3T27FnZbDaVLl3arX3JkiUqX7686tWrp9GjR3Pl9RrkdNxgbF8fP//8s9asWaMHH3wwyzTGdv79+VyvKI/bnoWxA1Y5deqU0tPTFRAQ4NYeEBCgkydPWlTVjccYoyeffFK33Xab6tev72rv2LGjevTooZCQEB06dEgTJkxQmzZt9M033/C/puZDs2bNtHjxYtWqVUs///yznnvuObVo0UJ79+51jePsxviRI0esKPeGEhsbq6SkJA0YMMDVxri+PvIylk+ePCkvLy+VKVMmyzwc0wsuOTlZ48aNU58+fVSqVClXe9++fVWtWjUFBgZqz549Gj9+vHbv3u26jRF5l9txg7F9fbz99tvy8/NT165d3doZ2/mX3bleUR63i3UgyXTlJ5vSH5365zYU3GOPPaZvv/1Wn332mVt7r169XN/Xr19fTZs2VUhIiNasWZPl4ICr69ixo+v78PBwNW/eXNWrV9fbb7/teiiSMX59LFy4UB07dlRwcLCrjXF9fRVkLDPeCy41NVX33XefMjIyNHfuXLdpgwcPdn1fv3591axZU02bNtWOHTvUuHHjoi61WCvocYOxfW0WLVqkvn37yuFwuLUztvPvaud6UtEct4v1LVvly5dXiRIlsiSwX375JUuaQ8EMHz5cq1evVnx8vCpXrpzjvEFBQQoJCdHBgweLqLobk4+Pj8LDw3Xw4EHX27YY44XvyJEj+uijj/TQQw/lOB/junDkZSwHBgbq8uXLOnPmzFXnQd6lpqaqZ8+eOnTokDZu3Oh2dSQ7jRs3lt1uZ6wXgj8fNxjbhW/Lli3av39/rsdwibGdm6ud6xXlcbtYBxIvLy81adIkyyW4jRs3qkWLFhZVdWMwxuixxx7TypUrtWnTJlWrVi3XZU6fPq1jx44pKCioCCq8caWkpCghIUFBQUGuS85XjvHLly/rk08+YYxfo+joaFWsWFF33313jvMxrgtHXsZykyZNZLfb3eZJTEzUnj17GO/5lBlGDh48qI8++kjlypXLdZm9e/cqNTWVsV4I/nzcYGwXvoULF6pJkyaKiIjIdV7GdvZyO9cr0uP2tTyN/1ewbNkyY7fbzcKFC82+ffvM448/bnx8fMzhw4etLq1Ye/TRR42/v7/ZvHmzSUxMdH1dvHjRGGPM+fPnzahRo8wXX3xhDh06ZOLj403z5s1NpUqVzLlz5yyuvngZNWqU2bx5s/nxxx/Ntm3bTOfOnY2fn59rDE+fPt34+/ublStXmu+++8707t3bBAUF0c/XID093VStWtWMHTvWrZ1xfW3Onz9vdu7caXbu3GkkmZdfftns3LnT9WanvIzlRx55xFSuXNl89NFHZseOHaZNmzYmIiLCpKWlWbVbf0k59XVqaqrp0qWLqVy5stm1a5fbMTwlJcUYY8x///tf8+yzz5rt27ebQ4cOmTVr1pg6deqYRo0a0dfZyKm/83rcYGznTW7HEWOMOXv2rClZsqSZN29eluUZ23mX27meMUV33C72gcQYY+bMmWNCQkKMl5eXady4sduraVEwkrL9io6ONsYYc/HiRdO+fXtToUIFY7fbTdWqVU3//v3N0aNHrS28GOrVq5cJCgoydrvdBAcHm65du5q9e/e6pmdkZJhJkyaZwMBA4+3tbVq1amW+++47Cysu/tavX28kmf3797u1M66vTXx8fLbHjf79+xtj8jaWL126ZB577DFTtmxZ43Q6TefOnen/bOTU14cOHbrqMTw+Pt4YY8zRo0dNq1atTNmyZY2Xl5epXr26GTFihDl9+rS1O/YXlVN/5/W4wdjOm9yOI8YYs2DBAuN0Ok1SUlKW5RnbeZfbuZ4xRXfctv1fQQAAAABQ5Ir1MyQAAAAAijcCCQAAAADLEEgAAAAAWIZAAgAAAMAyBBIAAAAAliGQAAAAALAMgQQAAACAZQgkAAAAACxDIAGA6yQmJkalS5e2ugxJUmxsrGrUqKESJUro8ccft7qcv6yFCxeqffv2rp8HDBigf/zjH9YVlIPu3bvr5ZdftroMALhmBBIAxdqAAQNks9lks9lkt9sVEBCgdu3aadGiRcrIyCiyOkJDQ/Xqq6+6tfXq1UsHDhwoshpyMmTIEHXv3l3Hjh3T1KlTs50nu33YuXOnevTooYCAADkcDtWqVUuDBw927dfmzZtls9mUlJSUZX0NGzbU5MmTr1rThQsXNHbsWIWFhcnhcKhChQqKjIxUXFxcjjVdLykpKZo4caImTJhQJNu7VhMnTtTzzz+vc+fOWV0KAFwTAgmAYu+uu+5SYmKiDh8+rLVr1+qOO+7QyJEj1blzZ6WlpRV4vcaYa1re6XSqYsWKBV6+sPz+++/65Zdf1KFDBwUHB8vPzy9Py8XFxenWW29VSkqKlixZooSEBL3zzjvy9/cvlJP2Rx55RLGxsZo9e7a+//57rVu3Tt26ddPp06eved0F8f7778vX11e33367Jdu/0uXLl3Odp0GDBgoNDdWSJUuKoCIAuH4IJACKPW9vbwUGBqpSpUpq3Lixnn76aX3wwQdau3atYmJiJEmHDx+WzWbTrl27XMslJSXJZrNp8+bNkv73af/69evVtGlTeXt7a8uWLfrhhx8UFRWlgIAA+fr66uabb9ZHH33kWk9kZKSOHDmiJ554wnW1Rsr+lq158+apevXq8vLyUu3atfXOO++4TbfZbHrrrbd07733qmTJkqpZs6ZWr16d4/6fOXNGDzzwgMqUKaOSJUuqY8eOOnjwoGufMgNImzZt3PY3JxcvXtTAgQPVqVMnrV69WnfeeaeqVaumZs2aadasWVqwYEGu68jNf/7zHz399NPq1KmTQkND1aRJEw0fPlz9+/eXdPV+PX36tHr37q3KlSurZMmSCg8P19KlS13rXbx4scqVK6eUlBS37XXr1k0PPPDAVetZtmyZunTpku20WbNmKSgoSOXKldOwYcOUmprqmpZT/0vS5MmT1bBhQ7f1vfrqqwoNDXX9nHlr2LRp0xQcHKxatWpJkubOnauaNWvK4XAoICBA3bt3d1tPly5d3PYdAIojAgmAG1KbNm0UERGhlStX5nvZMWPGaNq0aUpISFCDBg30+++/q1OnTvroo4+0c+dOdejQQffcc4+OHj0qSVq5cqUqV66sKVOmKDExUYmJidmud9WqVRo5cqRGjRqlPXv2aMiQIRo4cKDi4+Pd5nv22WfVs2dPffvtt+rUqZP69u2r33777ar1DhgwQF9//bVWr16trVu3yhijTp06KTU1VS1atND+/fsl/XEFIDExUS1atMi1D9avX69Tp05pzJgx2U4vjGdjAgMD9eGHH+r8+fPZTr9avyYnJ6tJkyaKi4vTnj179PDDD6tfv3768ssvJUk9evRQenq6W5A7deqU4uLiNHDgwKvWs2XLFjVt2jRLe3x8vH744QfFx8fr7bffVkxMjCvoSjn3f358/PHHSkhI0MaNGxUXF6evv/5aI0aM0JQpU7R//36tW7dOrVq1clvmlltu0VdffZUlfAFAcUIgAXDDqlOnjg4fPpzv5aZMmaJ27dqpevXqKleunCIiIjRkyBCFh4erZs2aeu655xQWFuY64S1btqxKlCghPz8/BQYGKjAwMNv1zpo1SwMGDNDQoUNVq1YtPfnkk+ratatmzZrlNt+AAQPUu3dv1ahRQy+88IIuXLigr776Ktt1Hjx4UKtXr9Zbb72l22+/XREREVqyZImOHz+u2NhYeXl5uW4bK1u2rAIDA+Xl5ZVrH2R+wl+nTp0891t+vfHGG/riiy9Urlw53XzzzXriiSf0+eefu6ZfrV8rVaqk0aNHq2HDhgoLC9Pw4cPVoUMHrVixQtIft8r16dNH0dHRrnUtWbJElStXVmRkZLa1JCUlKSkpScHBwVmmlSlTRrNnz1adOnXUuXNn3X333fr4448l5d7/+eHj46O33npL9erVU/369XX06FH5+Pioc+fOCgkJUaNGjTRixAi3ZSpVqqSUlBSdPHkyX9sCgL8SAgmAG5YxxnWbT378+VPyCxcuaMyYMbrppptUunRp+fr66vvvv3ddIcmrhIQEtWzZ0q2tZcuWSkhIcGtr0KCB63sfHx/5+fnpl19+ueo6PT091axZM1dbuXLlVLt27SzrzQ9jTIGXzatWrVrpxx9/1Mcff6xu3bpp7969uv3226/60H2m9PR0Pf/882rQoIHKlSsnX19fbdiwwe33MXjwYG3YsEHHjx+XJEVHR7tegJCdS5cuSZIcDkeWafXq1VOJEiVcPwcFBbl+H4XZ/+Hh4W5hsV27dgoJCVFYWJj69eunJUuW6OLFi27LOJ1OScrSDgDFCYEEwA0rISFB1apVkyR5ePxxuLvyRPtqt9T4+Pi4/fzUU0/p/fff1/PPP68tW7Zo165dCg8Pz9ODx3/25xPi7EKT3W7PsszV3hh2teBQ0DCWKfMZhu+//z7H+UqVKiVJOnv2bJZpSUlJ8vf3z3F5u92u22+/XePGjdOGDRs0ZcoUTZ06Nce+femll/TKK69ozJgx2rRpk3bt2qUOHTq4LdOoUSNFRERo8eLF2rFjh7777jsNGDDgqussV66cbDabzpw5k22NV7ry95GX/vfw8MgyX3Zj78/jzs/PTzt27NDSpUsVFBSkiRMnKiIiwu2NZpm38lWoUOGq+wYAf3UEEgA3pE2bNum7775Tt27dJP3vhO3K5zuufMA9J1u2bNGAAQN07733Kjw8XIGBgVluBfPy8lJ6enqO66lbt64+++wzt7YvvvhCdevWzVMd2bnpppuUlpbmen5C+uOh7wMHDlzTetu3b6/y5ctrxowZ2U7PPCmuWbOmPDw8tH37drfpiYmJOn78uGrXrp2v7WbuT3JysqTs+3XLli2KiorS/fffr4iICIWFhbk9RJ7poYceUnR0tBYtWqQ777xTVapUuep2vby8dNNNN2nfvn0Fqjen/q9QoYJOnjzpFkryOvY8PT115513asaMGfr22291+PBhbdq0yTV9z549qly5ssqXL5+vugHgr4RAAqDYy7yH/vjx49qxY4deeOEFRUVFqXPnzq63KjmdTt16662aPn269u3bp08//VTPPPNMntZfo0YNrVy5Urt27dLu3bvVp0+fLFcsQkND9emnn+r48eM6depUtut56qmnFBMTo/nz5+vgwYN6+eWXtXLlSo0ePbrA+16zZk1FRUVp8ODB+uyzz7R7927df//9qlSpkqKiogq83sznGdasWaMuXbroo48+0uHDh/X1119rzJgxeuSRRyT98Sn+kCFDNGrUKMXGxurQoUP6/PPP1bt3b9WtW9ftPxn8s8jISC1YsEDffPONDh8+rA8//FBPP/207rjjDteVl+z6tUaNGtq4caO++OILJSQkaMiQIdk+Q9G3b18dP35cb775pgYNGpTrPnfo0CFLYMxNXvo/MjJSv/76q2bMmKEffvhBc+bM0dq1a3Ndd1xcnP75z39q165dOnLkiBYvXqyMjAy3kLdly5Yc+xgAigUDAMVY//79jSQjyXh6epoKFSqYO++80yxatMikp6e7zbtv3z5z6623GqfTaRo2bGg2bNhgJJn4+HhjjDHx8fFGkjlz5ozbcocOHTJ33HGHcTqdpkqVKmb27NmmdevWZuTIka55tm7daho0aGC8vb1N5qE1Ojra+Pv7u61r7ty5JiwszNjtdlOrVi2zePFit+mSzKpVq9za/P39TXR09FX74LfffjP9+vUz/v7+xul0mg4dOpgDBw64pp85c8ZtP68mJCTEvPLKK25t27dvN127djUVKlQw3t7epkaNGubhhx82Bw8edM2TnJxspkyZYurWrWucTqcJCQkxAwYMMImJiTlu74UXXjDNmzc3ZcuWNQ6Hw4SFhZkRI0aYU6dOuebJrl9Pnz5toqKijK+vr6lYsaJ55plnzAMPPGCioqKybKNfv36mbNmyJjk5OcdajDEmISHBOJ1Ok5SU5Grr379/lvWOHDnStG7d2vVzbv1vjDHz5s0zVapUMT4+PuaBBx4wzz//vAkJCclxO1u2bDGtW7c2ZcqUMU6n0zRo0MAsX77cNf3SpUumVKlSZuvWrbnuGwD8ldmMKYInFwEAsEC7du1Ut25d/fOf/8zT/D179lSjRo00fvz461zZtZszZ44++OADbdiwwepSAOCacMsWAOCG89tvv2nZsmXatGmThg0bluflZs6cKV9f3+tYWeGx2+16/fXXrS4DAK4ZV0gAADec0NBQnTlzRhMmTLimZ3QAANcfgQQAAACAZbhlCwAAAIBlCCQAAAAALEMgAQAAAGAZAgkAAAAAyxBIAAAAAFiGQAIAAADAMgQSAAAAAJYhkAAAAACwzP8HodYlA9s7gTAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "sns.boxplot(x=filtered_diffs)\n",
    "plt.xlabel(\"Duration of ICU Stay (hours)\")\n",
    "plt.title(\"ICU Stay Duration (Outliers Removed)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d5ee8c",
   "metadata": {},
   "source": [
    "It seems a horizon length of 70 hours is suitable, as it accommodates all values below the 3rd quartile. This means all measurements within 70 hours of the first measurement (of any type) of an ICU stay will be considered in training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NUT5LDDo3wjh",
   "metadata": {
    "id": "NUT5LDDo3wjh"
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "MiIWHZzSyBeM",
   "metadata": {
    "id": "MiIWHZzSyBeM"
   },
   "outputs": [],
   "source": [
    "FREQ       = '2H'           # 2-hour bins\n",
    "MAX_HOURS  = 70              # Use 70 hours as per the earlier EDA on ICU stay lengths\n",
    "STEPS      = MAX_HOURS // 2  # 70 h ÷ 2 h = 35 bins\n",
    "L          = 6               # look-back  steps (12 hours of history)\n",
    "H          = 1               # look-ahead steps (direct subsequent prediction)\n",
    "SENTINEL   = -999.0            # value the Masking layer will ignore\n",
    "HYPER_LIMIT= 180             # Lowest value to be considered hyperglycemic\n",
    "HYPO_LIMIT = 70              # Highest value to be considered hypoglycemic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WI9SjVB8yB9q",
   "metadata": {
    "id": "WI9SjVB8yB9q"
   },
   "source": [
    "### Here we resample the data to ensure there is a row for every timestep interval of 2 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "JSTWAz_gx9Dh",
   "metadata": {
    "id": "JSTWAz_gx9Dh"
   },
   "outputs": [],
   "source": [
    "def resample_stay_multi(stay_id, dfs_by_feat):\n",
    "\n",
    "    mat = np.full((STEPS, F), np.nan, dtype='float32')\n",
    "\n",
    "    # Find earliest timestamp amongst all features\n",
    "    start_time = None\n",
    "    # Visit all feature dataframes one by one, and keep track of earliest recorded time\n",
    "    for df in dfs_by_feat.values():\n",
    "        s = df.loc[df['stay_id'] == stay_id, 'charttime']\n",
    "        if not s.empty:\n",
    "            t0 = s.min()\n",
    "            start_time = t0 if start_time is None else min(start_time, t0)\n",
    "\n",
    "    # Return None if none of the feature dfs have the stay_id\n",
    "    if start_time is None:\n",
    "        return None\n",
    "\n",
    "    # Standardise horizon length of icu stay measurements\n",
    "    horizon = pd.date_range(start=start_time.floor(FREQ),\n",
    "                            periods=STEPS,\n",
    "                            freq=FREQ)\n",
    "\n",
    "    # Fill one column of matrix per feature\n",
    "    for j, feat in enumerate(FEATURES):\n",
    "        g = dfs_by_feat[feat]\n",
    "        g = g[g['stay_id'] == stay_id]\n",
    "        if g.empty:\n",
    "          # Column remains NaNs\n",
    "            continue\n",
    "        s = (g.set_index('charttime')['value']\n",
    "               .resample(FREQ).mean())\n",
    "        # reindex sets length of values to be exactly STEPS length long,\n",
    "        # by trancating or padding with NaNs\n",
    "        mat[:, j] = s.reindex(horizon).values\n",
    "\n",
    "    return mat                       # (STEPS, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2cedc",
   "metadata": {
    "id": "aed2cedc"
   },
   "source": [
    "Here we create the data to be fed into the model. Each row of data in the X datasets is a sequence of BG measurements. The Y datasets contain a BG reading that follows directly from that sequence after.\n",
    "\n",
    "The approach we took is so that a sequence of measurements (starting from the first) is created of certain length from each ICU admission, which is taken as the X, and the following value after the sequence is taken as the Y. Then the window is slid over by one so that the sequence is slightly different, creating a new X value and a new following Y value. This process is repeated until the end of the ICU admission measurement sequence is reached, then a new ICU admission is chosen, until all ICU admissions have had their sequences recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c620e1",
   "metadata": {},
   "source": [
    "We also allow the data to be split into 2 parts if a decompensation event occurred. If the before_decomp variable is true, then it takes the data from before the first decompensation and puts it in the training data. Otherwise it uses the latter half. This is to ensure that one LSTM model is trained on pre-decompensation data and another is trained on post-decompensation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9JFB1xgjyNQM",
   "metadata": {
    "id": "9JFB1xgjyNQM"
   },
   "outputs": [],
   "source": [
    "def make_Xy_multi(subj_ids, fit_scaler=False, scaler_dict=None, before_decomp=True):\n",
    "    X_stays = []\n",
    "\n",
    "    # Create dictionary of all feature dataframes for the current split\n",
    "    dfs_by_feat = {}\n",
    "    for feat, df in MEAS_CLEAN.items():\n",
    "        df_ = df[df['subject_id'].isin(subj_ids)].copy()\n",
    "        df_['charttime'] = pd.to_datetime(df_['charttime'])\n",
    "        \n",
    "        # Here we change data to use before first decompensation or after\n",
    "        if feat == 'bg':\n",
    "            \n",
    "            filtered_stays = []  # list to collect filtered DataFrames\n",
    "            \n",
    "            for stay_id in df_['stay_id'].unique():\n",
    "                stay = df_[df_['stay_id'] == stay_id].sort_values(by=['charttime']).reset_index(drop=True)\n",
    "                \n",
    "                condition = (stay['value'] >= HYPER_LIMIT) | (stay['value'] <= HYPO_LIMIT)\n",
    "                if condition.any():\n",
    "                    decomp = condition.idxmax()  # gets the index of the first True value\n",
    "                    # If before_decomp is true, then select all rows or measurements occurring before the first decompensation\n",
    "                    if before_decomp:\n",
    "                        filtered_stays.append(stay.iloc[:decomp + 1])\n",
    "                    else:\n",
    "                    # Otherwise after\n",
    "                        filtered_stays.append(stay.iloc[decomp + 1:])\n",
    "                else:\n",
    "                    filtered_stays.append(stay)\n",
    "            # Combine the generated dataframe and set it as the BG dataframe\n",
    "            df_ = pd.concat(filtered_stays, ignore_index=True)\n",
    "        dfs_by_feat[feat] = df_\n",
    "\n",
    "    # Retrieve all unique stay_ids across all feature dataframes\n",
    "    all_stays = pd.concat([d[['stay_id']] for d in dfs_by_feat.values()]\n",
    "                          ).drop_duplicates()['stay_id'].values\n",
    "    # Creates a list of (STEPS, F) matrices\n",
    "    for sid in all_stays:\n",
    "        M = resample_stay_multi(sid, dfs_by_feat)   # (STEPS, F) or None\n",
    "        # Only append the matrix if at least one of the dataframes contains a value\n",
    "        if M is not None:\n",
    "            X_stays.append(M)\n",
    "\n",
    "    # Convert to list of stays to 3D tensor shape\n",
    "    X_stays = np.stack(X_stays)          # (N_stays, STEPS, F)\n",
    "\n",
    "    # Feature-wise Standardisation\n",
    "    if scaler_dict is None:\n",
    "        scaler_dict = {}\n",
    "    for j in range(F):\n",
    "        # Concatenate all feature j columns across all stays, include every row, stack them\n",
    "        col = X_stays[:, :, j].ravel()\n",
    "        # NaN mask\n",
    "        mask = ~np.isnan(col)\n",
    "        if fit_scaler:\n",
    "            mu = np.nanmean(col)\n",
    "            sd = np.nanstd(col)\n",
    "            # Protects program from division-by-zero error by ensuring if col is all NaNs, 0 is replaced with 1\n",
    "            sd = sd if sd != 0 else 1.0\n",
    "            scaler_dict[j] = (mu, sd)\n",
    "        # Retrieves values for std and mean for when non-training splits are scaled\n",
    "        mu, sd = scaler_dict[j]\n",
    "        # Scales non-NaN data\n",
    "        col[mask] = (col[mask] - mu) / sd\n",
    "\n",
    "        # Sets a slice of dimension (X_stays.shape[0], STEPS) of a particular feature to the col variable\n",
    "        X_stays[:, :, j] = col.reshape(X_stays.shape[0], STEPS)\n",
    "\n",
    "    # Sliding window\n",
    "    windows, targets = [], []\n",
    "    for stay in X_stays:\n",
    "        # Window slides across every point so that the entire horizon of the ICU stay is included once\n",
    "        for t0 in range(0, STEPS - L - H + 1):\n",
    "            x_win = stay[t0 : t0 + L, :]                # Look-back window\n",
    "            y_val = stay[t0 + L + H - 1, GLU_IDX]       # Glucose value following window\n",
    "            if not np.isnan(y_val):                     # ensure that the final y value is an actual value\n",
    "                windows.append(x_win)\n",
    "                targets.append(y_val)\n",
    "\n",
    "    X = np.array(windows, dtype='float32')             # (N, L, F)\n",
    "    y = np.array(targets, dtype='float32')             # (N,)\n",
    "\n",
    "    # mask NaN timesteps\n",
    "    X[np.isnan(X)] = SENTINEL\n",
    "    return X, y, scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc3a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('Pickles', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "p2166dlHEGBg",
   "metadata": {
    "id": "p2166dlHEGBg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_before set -> 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_before, y_train_before, SCALERS_BEFORE = make_Xy_multi(SPLIT['train'], fit_scaler=True, before_decomp=True)\n",
    "\n",
    "# Save train data and scalers immediately\n",
    "train_before_path = 'Pickles/split_before_glu_train.pkl.gz'\n",
    "with gzip.open(train_before_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train_before,\n",
    "        'y_train': y_train_before,\n",
    "        'scalers': SCALERS_BEFORE\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved train_before set -> {os.path.getsize(train_before_path)/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f485b16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_before set -> 11.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_after, y_train_after, SCALERS_AFTER = make_Xy_multi(SPLIT['train'], fit_scaler=True, before_decomp=False)\n",
    "\n",
    "# Save train data and scalers immediately\n",
    "train_after_path = 'Pickles/split_after_glu_train.pkl.gz'\n",
    "with gzip.open(train_after_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_train': X_train_after,\n",
    "        'y_train': y_train_after,\n",
    "        'scalers': SCALERS_AFTER\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved train_before set -> {os.path.getsize(train_after_path)/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "G-JcyoOjERA-",
   "metadata": {
    "id": "G-JcyoOjERA-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation set -> 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_val_before, y_val_before, _ = make_Xy_multi(SPLIT['val'], scaler_dict=SCALERS_BEFORE, before_decomp=True)\n",
    "\n",
    "# Save val data immediately\n",
    "val_path_before = 'Pickles/split_before_glu_val.pkl.gz'\n",
    "with gzip.open(val_path_before, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_val': X_val_before,\n",
    "        'y_val': y_val_before\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved validation set -> {os.path.getsize(val_path_before)/1e6:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f400782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation set -> 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_val_after, y_val_after, _ = make_Xy_multi(SPLIT['val'], scaler_dict=SCALERS_AFTER, before_decomp=False)\n",
    "\n",
    "# Save val data immediately\n",
    "val_path_after = 'Pickles/split_after_glu_val.pkl.gz'\n",
    "with gzip.open(val_path_after, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_val': X_val_after,\n",
    "        'y_val': y_val_after\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved validation set -> {os.path.getsize(val_path_after)/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cvTuKx1bEWvS",
   "metadata": {
    "id": "cvTuKx1bEWvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test set -> 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_test_before, y_test_before, _ = make_Xy_multi(SPLIT['test'], scaler_dict=SCALERS_BEFORE, before_decomp=True)\n",
    "\n",
    "# Save test data immediately\n",
    "test_path_before = 'Pickles/split_before_glu_test.pkl.gz'\n",
    "with gzip.open(test_path_before, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_test': X_test_before,\n",
    "        'y_test': y_test_before\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved test set -> {os.path.getsize(test_path_before)/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa676db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test set -> 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_test_after, y_test_after, _ = make_Xy_multi(SPLIT['test'], scaler_dict=SCALERS_AFTER, before_decomp=False)\n",
    "\n",
    "# Save test data immediately\n",
    "test_path_after = 'Pickles/split_after_glu_test.pkl.gz'\n",
    "with gzip.open(test_path_after, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X_test': X_test_after,\n",
    "        'y_test': y_test_after\n",
    "    }, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(f\"Saved test set -> {os.path.getsize(test_path_after)/1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ef4fcb9f",
   "metadata": {
    "id": "myv077YiwTuS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose  μ=130.6  σ=50.8\n"
     ]
    }
   ],
   "source": [
    "# After you build SCALERS in make_Xy_multi\n",
    "mu_glu_before, std_glu_before = SCALERS_BEFORE[GLU_IDX]          \n",
    "print(f\"Glucose  μ={mu_glu_before:.1f}  σ={std_glu_before:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "myv077YiwTuS",
   "metadata": {
    "id": "myv077YiwTuS",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glucose  μ=148.2  σ=62.6\n"
     ]
    }
   ],
   "source": [
    "# After you build SCALERS in make_Xy_multi\n",
    "mu_glu_after, std_glu_after = SCALERS_AFTER[GLU_IDX]         \n",
    "print(f\"Glucose  μ={mu_glu_after:.1f}  σ={std_glu_after:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "EFRdNVBm_C1Z",
   "metadata": {
    "id": "EFRdNVBm_C1Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Pre-Decomp--------\n",
      "Train: (137914, 6, 10) (137914,)\n",
      "Val  : (46103, 6, 10) (46103,)\n",
      "Test : (45965, 6, 10) (45965,)\n",
      "--------Post-Decomp--------\n",
      "Train: (290442, 6, 10) (290442,)\n",
      "Val  : (97896, 6, 10) (97896,)\n",
      "Test : (96863, 6, 10) (96863,)\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Pre-Decomp--------\")\n",
    "print(\"Train:\", X_train_before.shape, y_train_before.shape)\n",
    "print(\"Val  :\", X_val_before.shape,   y_val_before.shape)\n",
    "print(\"Test :\", X_test_before.shape,  y_test_before.shape)\n",
    "print(\"--------Post-Decomp--------\")\n",
    "print(\"Train:\", X_train_after.shape, y_train_after.shape)\n",
    "print(\"Val  :\", X_val_after.shape,   y_val_after.shape)\n",
    "print(\"Test :\", X_test_after.shape,  y_test_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "EdDbLesv5Hdy",
   "metadata": {
    "id": "EdDbLesv5Hdy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any NaN in y_train_before ? False\n",
      "Any NaN in X_train_before ? False\n",
      "Any NaN in y_train_after ? False\n",
      "Any NaN in X_train_after ? False\n",
      "NaN count (before): 0\n",
      "NaN count (after): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Any NaN in y_train_before ?\", np.isnan(y_train_before).any())\n",
    "print(\"Any NaN in X_train_before ?\", np.isnan(X_train_before).any())\n",
    "\n",
    "print(\"Any NaN in y_train_after ?\", np.isnan(y_train_after).any())\n",
    "print(\"Any NaN in X_train_after ?\", np.isnan(X_train_after).any())\n",
    "# How many?\n",
    "print(\"NaN count (before):\", np.isnan(X_train_before).sum())\n",
    "print(\"NaN count (after):\", np.isnan(X_train_after).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "USMpFcAiLKOE",
   "metadata": {
    "id": "USMpFcAiLKOE"
   },
   "outputs": [],
   "source": [
    "BATCH = 64\n",
    "def make_ds(X, y, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(y), seed=seed)\n",
    "    return ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "gZXuchmOLMf5",
   "metadata": {
    "id": "gZXuchmOLMf5"
   },
   "outputs": [],
   "source": [
    "ds_train_before = make_ds(X_train_before, y_train_before, shuffle=True)\n",
    "ds_val_before   = make_ds(X_val_before,   y_val_before,   shuffle=False)\n",
    "ds_test_before  = make_ds(X_test_before,  y_test_before,  shuffle=False)\n",
    "\n",
    "ds_train_after = make_ds(X_train_after, y_train_after, shuffle=True)\n",
    "ds_val_after   = make_ds(X_val_after,   y_val_after,   shuffle=False)\n",
    "ds_test_after  = make_ds(X_test_after,  y_test_after,  shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4f35e2",
   "metadata": {},
   "source": [
    "# Pre-decompensation LSTM model\n",
    "\n",
    "Below here we train a LSTM model using data from before a patient's first decompensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27DSFKlALWUJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "27DSFKlALWUJ",
    "outputId": "7a85fc99-c884-4c41-82e2-f0248ab6c99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 6, 10)             0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                19200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,313\n",
      "Trainable params: 21,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_before = tf.keras.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=SENTINEL, input_shape=(L, F)),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    # A dense layer here is necessary, as each hidden state output, which is\n",
    "    # the output of an LSTM unit is only within the range of a tanh activation function,\n",
    "    # so further transformation is needed\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)                   # regression\n",
    "])\n",
    "\n",
    "model_before.compile(loss='mse', optimizer='adam', metrics=['mae', RootMeanSquaredError(name='rmse'), 'mse'])\n",
    "model_before.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "iCItqTtdO1sS",
   "metadata": {
    "id": "iCItqTtdO1sS"
   },
   "outputs": [],
   "source": [
    "# Create directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "yfy1ukOPLYTR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfy1ukOPLYTR",
    "outputId": "7e65fdc0-b857-4785-c00f-661b0207ed1c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2144/2155 [============================>.] - ETA: 0s - loss: 0.5085 - mae: 0.4615 - rmse: 0.7131 - mse: 0.5085\n",
      "Epoch 1: saving model to models\\preDecomp_multivar_epoch_01.h5\n",
      "2155/2155 [==============================] - 12s 4ms/step - loss: 0.5076 - mae: 0.4614 - rmse: 0.7124 - mse: 0.5076 - val_loss: 0.4780 - val_mae: 0.4617 - val_rmse: 0.6913 - val_mse: 0.4780\n",
      "Epoch 2/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5032 - mae: 0.4585 - rmse: 0.7093 - mse: 0.5032\n",
      "Epoch 2: saving model to models\\preDecomp_multivar_epoch_02.h5\n",
      "2155/2155 [==============================] - 9s 4ms/step - loss: 0.5037 - mae: 0.4586 - rmse: 0.7097 - mse: 0.5037 - val_loss: 0.4778 - val_mae: 0.4575 - val_rmse: 0.6912 - val_mse: 0.4778\n",
      "Epoch 3/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.5040 - mae: 0.4588 - rmse: 0.7100 - mse: 0.5040\n",
      "Epoch 3: saving model to models\\preDecomp_multivar_epoch_03.h5\n",
      "2155/2155 [==============================] - 10s 4ms/step - loss: 0.5040 - mae: 0.4588 - rmse: 0.7099 - mse: 0.5040 - val_loss: 0.4775 - val_mae: 0.4582 - val_rmse: 0.6910 - val_mse: 0.4775\n",
      "Epoch 4/100\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.5031 - mae: 0.4578 - rmse: 0.7093 - mse: 0.5031\n",
      "Epoch 4: saving model to models\\preDecomp_multivar_epoch_04.h5\n",
      "2155/2155 [==============================] - 10s 5ms/step - loss: 0.5029 - mae: 0.4578 - rmse: 0.7091 - mse: 0.5029 - val_loss: 0.4769 - val_mae: 0.4548 - val_rmse: 0.6905 - val_mse: 0.4769\n",
      "Epoch 5/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.5027 - mae: 0.4577 - rmse: 0.7090 - mse: 0.5027\n",
      "Epoch 5: saving model to models\\preDecomp_multivar_epoch_05.h5\n",
      "2155/2155 [==============================] - 11s 5ms/step - loss: 0.5027 - mae: 0.4577 - rmse: 0.7090 - mse: 0.5027 - val_loss: 0.4769 - val_mae: 0.4555 - val_rmse: 0.6906 - val_mse: 0.4769\n",
      "Epoch 6/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.5030 - mae: 0.4579 - rmse: 0.7092 - mse: 0.5030\n",
      "Epoch 6: saving model to models\\preDecomp_multivar_epoch_06.h5\n",
      "2155/2155 [==============================] - 12s 5ms/step - loss: 0.5027 - mae: 0.4579 - rmse: 0.7090 - mse: 0.5027 - val_loss: 0.4777 - val_mae: 0.4553 - val_rmse: 0.6912 - val_mse: 0.4777\n",
      "Epoch 7/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.5025 - mae: 0.4577 - rmse: 0.7089 - mse: 0.5025\n",
      "Epoch 7: saving model to models\\preDecomp_multivar_epoch_07.h5\n",
      "2155/2155 [==============================] - 12s 5ms/step - loss: 0.5029 - mae: 0.4577 - rmse: 0.7091 - mse: 0.5029 - val_loss: 0.4768 - val_mae: 0.4607 - val_rmse: 0.6905 - val_mse: 0.4768\n",
      "Epoch 8/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5030 - mae: 0.4578 - rmse: 0.7092 - mse: 0.5030\n",
      "Epoch 8: saving model to models\\preDecomp_multivar_epoch_08.h5\n",
      "2155/2155 [==============================] - 12s 6ms/step - loss: 0.5027 - mae: 0.4577 - rmse: 0.7090 - mse: 0.5027 - val_loss: 0.4772 - val_mae: 0.4598 - val_rmse: 0.6908 - val_mse: 0.4772\n",
      "Epoch 9/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5031 - mae: 0.4580 - rmse: 0.7093 - mse: 0.5031\n",
      "Epoch 9: saving model to models\\preDecomp_multivar_epoch_09.h5\n",
      "2155/2155 [==============================] - 12s 6ms/step - loss: 0.5029 - mae: 0.4580 - rmse: 0.7092 - mse: 0.5029 - val_loss: 0.4782 - val_mae: 0.4543 - val_rmse: 0.6915 - val_mse: 0.4782\n",
      "Epoch 10/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.5029 - mae: 0.4575 - rmse: 0.7091 - mse: 0.5029\n",
      "Epoch 10: saving model to models\\preDecomp_multivar_epoch_10.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5028 - mae: 0.4575 - rmse: 0.7091 - mse: 0.5028 - val_loss: 0.4766 - val_mae: 0.4558 - val_rmse: 0.6904 - val_mse: 0.4766\n",
      "Epoch 11/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5029 - mae: 0.4577 - rmse: 0.7091 - mse: 0.5029\n",
      "Epoch 11: saving model to models\\preDecomp_multivar_epoch_11.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5025 - mae: 0.4576 - rmse: 0.7089 - mse: 0.5025 - val_loss: 0.4765 - val_mae: 0.4554 - val_rmse: 0.6903 - val_mse: 0.4765\n",
      "Epoch 12/100\n",
      "2147/2155 [============================>.] - ETA: 0s - loss: 0.5022 - mae: 0.4567 - rmse: 0.7087 - mse: 0.5022\n",
      "Epoch 12: saving model to models\\preDecomp_multivar_epoch_12.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5018 - mae: 0.4567 - rmse: 0.7084 - mse: 0.5018 - val_loss: 0.4762 - val_mae: 0.4578 - val_rmse: 0.6901 - val_mse: 0.4762\n",
      "Epoch 13/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5018 - mae: 0.4566 - rmse: 0.7084 - mse: 0.5018\n",
      "Epoch 13: saving model to models\\preDecomp_multivar_epoch_13.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5016 - mae: 0.4567 - rmse: 0.7083 - mse: 0.5016 - val_loss: 0.4764 - val_mae: 0.4542 - val_rmse: 0.6902 - val_mse: 0.4764\n",
      "Epoch 14/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.5012 - mae: 0.4560 - rmse: 0.7079 - mse: 0.5012\n",
      "Epoch 14: saving model to models\\preDecomp_multivar_epoch_14.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5013 - mae: 0.4561 - rmse: 0.7080 - mse: 0.5013 - val_loss: 0.4760 - val_mae: 0.4591 - val_rmse: 0.6900 - val_mse: 0.4760\n",
      "Epoch 15/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5016 - mae: 0.4564 - rmse: 0.7083 - mse: 0.5016\n",
      "Epoch 15: saving model to models\\preDecomp_multivar_epoch_15.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5016 - mae: 0.4564 - rmse: 0.7082 - mse: 0.5016 - val_loss: 0.4760 - val_mae: 0.4549 - val_rmse: 0.6899 - val_mse: 0.4760\n",
      "Epoch 16/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5014 - mae: 0.4561 - rmse: 0.7081 - mse: 0.5014\n",
      "Epoch 16: saving model to models\\preDecomp_multivar_epoch_16.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5013 - mae: 0.4561 - rmse: 0.7080 - mse: 0.5013 - val_loss: 0.4760 - val_mae: 0.4560 - val_rmse: 0.6899 - val_mse: 0.4760\n",
      "Epoch 17/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.5017 - mae: 0.4562 - rmse: 0.7083 - mse: 0.5017\n",
      "Epoch 17: saving model to models\\preDecomp_multivar_epoch_17.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5013 - mae: 0.4562 - rmse: 0.7080 - mse: 0.5013 - val_loss: 0.4765 - val_mae: 0.4549 - val_rmse: 0.6903 - val_mse: 0.4765\n",
      "Epoch 18/100\n",
      "2146/2155 [============================>.] - ETA: 0s - loss: 0.5017 - mae: 0.4560 - rmse: 0.7083 - mse: 0.5017\n",
      "Epoch 18: saving model to models\\preDecomp_multivar_epoch_18.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.5012 - mae: 0.4560 - rmse: 0.7080 - mse: 0.5012 - val_loss: 0.4753 - val_mae: 0.4557 - val_rmse: 0.6894 - val_mse: 0.4753\n",
      "Epoch 19/100\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.5008 - mae: 0.4554 - rmse: 0.7076 - mse: 0.5008\n",
      "Epoch 19: saving model to models\\preDecomp_multivar_epoch_19.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5007 - mae: 0.4555 - rmse: 0.7076 - mse: 0.5007 - val_loss: 0.4764 - val_mae: 0.4529 - val_rmse: 0.6902 - val_mse: 0.4764\n",
      "Epoch 20/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5007 - mae: 0.4557 - rmse: 0.7076 - mse: 0.5007\n",
      "Epoch 20: saving model to models\\preDecomp_multivar_epoch_20.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.5006 - mae: 0.4557 - rmse: 0.7076 - mse: 0.5006 - val_loss: 0.4763 - val_mae: 0.4620 - val_rmse: 0.6901 - val_mse: 0.4763\n",
      "Epoch 21/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5006 - mae: 0.4555 - rmse: 0.7076 - mse: 0.5006\n",
      "Epoch 21: saving model to models\\preDecomp_multivar_epoch_21.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.5007 - mae: 0.4556 - rmse: 0.7076 - mse: 0.5007 - val_loss: 0.4757 - val_mae: 0.4594 - val_rmse: 0.6897 - val_mse: 0.4757\n",
      "Epoch 22/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5005 - mae: 0.4552 - rmse: 0.7074 - mse: 0.5005\n",
      "Epoch 22: saving model to models\\preDecomp_multivar_epoch_22.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5004 - mae: 0.4553 - rmse: 0.7074 - mse: 0.5004 - val_loss: 0.4748 - val_mae: 0.4583 - val_rmse: 0.6891 - val_mse: 0.4748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "2149/2155 [============================>.] - ETA: 0s - loss: 0.4994 - mae: 0.4546 - rmse: 0.7067 - mse: 0.4994\n",
      "Epoch 23: saving model to models\\preDecomp_multivar_epoch_23.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4997 - mae: 0.4546 - rmse: 0.7069 - mse: 0.4997 - val_loss: 0.4748 - val_mae: 0.4529 - val_rmse: 0.6891 - val_mse: 0.4748\n",
      "Epoch 24/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5003 - mae: 0.4550 - rmse: 0.7073 - mse: 0.5003\n",
      "Epoch 24: saving model to models\\preDecomp_multivar_epoch_24.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.5001 - mae: 0.4550 - rmse: 0.7072 - mse: 0.5001 - val_loss: 0.4760 - val_mae: 0.4530 - val_rmse: 0.6899 - val_mse: 0.4760\n",
      "Epoch 25/100\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.5006 - mae: 0.4551 - rmse: 0.7076 - mse: 0.5006\n",
      "Epoch 25: saving model to models\\preDecomp_multivar_epoch_25.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.5004 - mae: 0.4550 - rmse: 0.7074 - mse: 0.5004 - val_loss: 0.4748 - val_mae: 0.4544 - val_rmse: 0.6890 - val_mse: 0.4748\n",
      "Epoch 26/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5003 - mae: 0.4549 - rmse: 0.7073 - mse: 0.5003\n",
      "Epoch 26: saving model to models\\preDecomp_multivar_epoch_26.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.5001 - mae: 0.4549 - rmse: 0.7072 - mse: 0.5001 - val_loss: 0.4748 - val_mae: 0.4534 - val_rmse: 0.6891 - val_mse: 0.4748\n",
      "Epoch 27/100\n",
      "2149/2155 [============================>.] - ETA: 0s - loss: 0.5006 - mae: 0.4549 - rmse: 0.7075 - mse: 0.5006\n",
      "Epoch 27: saving model to models\\preDecomp_multivar_epoch_27.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5002 - mae: 0.4549 - rmse: 0.7073 - mse: 0.5002 - val_loss: 0.4745 - val_mae: 0.4532 - val_rmse: 0.6889 - val_mse: 0.4745\n",
      "Epoch 28/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.5000 - mae: 0.4549 - rmse: 0.7071 - mse: 0.5000\n",
      "Epoch 28: saving model to models\\preDecomp_multivar_epoch_28.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.5000 - mae: 0.4549 - rmse: 0.7071 - mse: 0.5000 - val_loss: 0.4753 - val_mae: 0.4527 - val_rmse: 0.6894 - val_mse: 0.4753\n",
      "Epoch 29/100\n",
      "2149/2155 [============================>.] - ETA: 0s - loss: 0.5000 - mae: 0.4544 - rmse: 0.7071 - mse: 0.5000\n",
      "Epoch 29: saving model to models\\preDecomp_multivar_epoch_29.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4996 - mae: 0.4544 - rmse: 0.7068 - mse: 0.4996 - val_loss: 0.4738 - val_mae: 0.4532 - val_rmse: 0.6884 - val_mse: 0.4738\n",
      "Epoch 30/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.4991 - mae: 0.4540 - rmse: 0.7064 - mse: 0.4991\n",
      "Epoch 30: saving model to models\\preDecomp_multivar_epoch_30.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4990 - mae: 0.4540 - rmse: 0.7064 - mse: 0.4990 - val_loss: 0.4738 - val_mae: 0.4543 - val_rmse: 0.6883 - val_mse: 0.4738\n",
      "Epoch 31/100\n",
      "2146/2155 [============================>.] - ETA: 0s - loss: 0.4991 - mae: 0.4541 - rmse: 0.7064 - mse: 0.4991\n",
      "Epoch 31: saving model to models\\preDecomp_multivar_epoch_31.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4991 - mae: 0.4541 - rmse: 0.7065 - mse: 0.4991 - val_loss: 0.4743 - val_mae: 0.4574 - val_rmse: 0.6887 - val_mse: 0.4743\n",
      "Epoch 32/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.4997 - mae: 0.4543 - rmse: 0.7069 - mse: 0.4997\n",
      "Epoch 32: saving model to models\\preDecomp_multivar_epoch_32.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4994 - mae: 0.4543 - rmse: 0.7067 - mse: 0.4994 - val_loss: 0.4745 - val_mae: 0.4522 - val_rmse: 0.6889 - val_mse: 0.4745\n",
      "Epoch 33/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.4996 - mae: 0.4544 - rmse: 0.7068 - mse: 0.4996\n",
      "Epoch 33: saving model to models\\preDecomp_multivar_epoch_33.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4995 - mae: 0.4544 - rmse: 0.7068 - mse: 0.4995 - val_loss: 0.4740 - val_mae: 0.4545 - val_rmse: 0.6885 - val_mse: 0.4740\n",
      "Epoch 34/100\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.4996 - mae: 0.4542 - rmse: 0.7068 - mse: 0.4996\n",
      "Epoch 34: saving model to models\\preDecomp_multivar_epoch_34.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4994 - mae: 0.4543 - rmse: 0.7067 - mse: 0.4994 - val_loss: 0.4739 - val_mae: 0.4555 - val_rmse: 0.6884 - val_mse: 0.4739\n",
      "Epoch 35/100\n",
      "2147/2155 [============================>.] - ETA: 0s - loss: 0.4991 - mae: 0.4536 - rmse: 0.7065 - mse: 0.4991\n",
      "Epoch 35: saving model to models\\preDecomp_multivar_epoch_35.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4987 - mae: 0.4537 - rmse: 0.7062 - mse: 0.4987 - val_loss: 0.4745 - val_mae: 0.4546 - val_rmse: 0.6888 - val_mse: 0.4745\n",
      "Epoch 36/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.4993 - mae: 0.4539 - rmse: 0.7066 - mse: 0.4993\n",
      "Epoch 36: saving model to models\\preDecomp_multivar_epoch_36.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4991 - mae: 0.4539 - rmse: 0.7064 - mse: 0.4991 - val_loss: 0.4743 - val_mae: 0.4566 - val_rmse: 0.6887 - val_mse: 0.4743\n",
      "Epoch 37/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4997 - mae: 0.4541 - rmse: 0.7069 - mse: 0.4997\n",
      "Epoch 37: saving model to models\\preDecomp_multivar_epoch_37.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4992 - mae: 0.4541 - rmse: 0.7066 - mse: 0.4992 - val_loss: 0.4745 - val_mae: 0.4526 - val_rmse: 0.6889 - val_mse: 0.4745\n",
      "Epoch 38/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.4990 - mae: 0.4539 - rmse: 0.7064 - mse: 0.4990\n",
      "Epoch 38: saving model to models\\preDecomp_multivar_epoch_38.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4991 - mae: 0.4539 - rmse: 0.7064 - mse: 0.4991 - val_loss: 0.4749 - val_mae: 0.4581 - val_rmse: 0.6891 - val_mse: 0.4749\n",
      "Epoch 39/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.4990 - mae: 0.4540 - rmse: 0.7064 - mse: 0.4990\n",
      "Epoch 39: saving model to models\\preDecomp_multivar_epoch_39.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4990 - mae: 0.4540 - rmse: 0.7064 - mse: 0.4990 - val_loss: 0.4743 - val_mae: 0.4562 - val_rmse: 0.6887 - val_mse: 0.4743\n",
      "Epoch 40/100\n",
      "2149/2155 [============================>.] - ETA: 0s - loss: 0.4998 - mae: 0.4545 - rmse: 0.7069 - mse: 0.4998\n",
      "Epoch 40: saving model to models\\preDecomp_multivar_epoch_40.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4992 - mae: 0.4544 - rmse: 0.7066 - mse: 0.4992 - val_loss: 0.4753 - val_mae: 0.4562 - val_rmse: 0.6894 - val_mse: 0.4753\n",
      "Epoch 41/100\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.5007 - mae: 0.4555 - rmse: 0.7076 - mse: 0.5007\n",
      "Epoch 41: saving model to models\\preDecomp_multivar_epoch_41.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5004 - mae: 0.4554 - rmse: 0.7074 - mse: 0.5004 - val_loss: 0.4763 - val_mae: 0.4538 - val_rmse: 0.6902 - val_mse: 0.4763\n",
      "Epoch 42/100\n",
      "2146/2155 [============================>.] - ETA: 0s - loss: 0.5016 - mae: 0.4559 - rmse: 0.7082 - mse: 0.5016\n",
      "Epoch 42: saving model to models\\preDecomp_multivar_epoch_42.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.5007 - mae: 0.4557 - rmse: 0.7076 - mse: 0.5007 - val_loss: 0.4755 - val_mae: 0.4545 - val_rmse: 0.6896 - val_mse: 0.4755\n",
      "Epoch 43/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5009 - mae: 0.4557 - rmse: 0.7077 - mse: 0.5009\n",
      "Epoch 43: saving model to models\\preDecomp_multivar_epoch_43.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5005 - mae: 0.4556 - rmse: 0.7075 - mse: 0.5005 - val_loss: 0.4750 - val_mae: 0.4557 - val_rmse: 0.6892 - val_mse: 0.4750\n",
      "Epoch 44/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.5002 - mae: 0.4554 - rmse: 0.7073 - mse: 0.5002\n",
      "Epoch 44: saving model to models\\preDecomp_multivar_epoch_44.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5002 - mae: 0.4554 - rmse: 0.7073 - mse: 0.5002 - val_loss: 0.4762 - val_mae: 0.4580 - val_rmse: 0.6900 - val_mse: 0.4762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5008 - mae: 0.4557 - rmse: 0.7077 - mse: 0.5008\n",
      "Epoch 45: saving model to models\\preDecomp_multivar_epoch_45.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.5007 - mae: 0.4557 - rmse: 0.7076 - mse: 0.5007 - val_loss: 0.4753 - val_mae: 0.4550 - val_rmse: 0.6894 - val_mse: 0.4753\n",
      "Epoch 46/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.5001 - mae: 0.4555 - rmse: 0.7072 - mse: 0.5001\n",
      "Epoch 46: saving model to models\\preDecomp_multivar_epoch_46.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5003 - mae: 0.4556 - rmse: 0.7074 - mse: 0.5003 - val_loss: 0.4754 - val_mae: 0.4574 - val_rmse: 0.6895 - val_mse: 0.4754\n",
      "Epoch 47/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.5008 - mae: 0.4556 - rmse: 0.7077 - mse: 0.5008\n",
      "Epoch 47: saving model to models\\preDecomp_multivar_epoch_47.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.5006 - mae: 0.4557 - rmse: 0.7075 - mse: 0.5006 - val_loss: 0.4755 - val_mae: 0.4563 - val_rmse: 0.6895 - val_mse: 0.4755\n",
      "Epoch 48/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.5002 - mae: 0.4554 - rmse: 0.7073 - mse: 0.5002\n",
      "Epoch 48: saving model to models\\preDecomp_multivar_epoch_48.h5\n",
      "2155/2155 [==============================] - 16s 7ms/step - loss: 0.5002 - mae: 0.4554 - rmse: 0.7073 - mse: 0.5002 - val_loss: 0.4755 - val_mae: 0.4566 - val_rmse: 0.6896 - val_mse: 0.4755\n",
      "Epoch 49/100\n",
      "2149/2155 [============================>.] - ETA: 0s - loss: 0.5006 - mae: 0.4552 - rmse: 0.7075 - mse: 0.5006\n",
      "Epoch 49: saving model to models\\preDecomp_multivar_epoch_49.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4999 - mae: 0.4550 - rmse: 0.7070 - mse: 0.4999 - val_loss: 0.4750 - val_mae: 0.4561 - val_rmse: 0.6892 - val_mse: 0.4750\n",
      "Epoch 50/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4998 - mae: 0.4545 - rmse: 0.7070 - mse: 0.4998\n",
      "Epoch 50: saving model to models\\preDecomp_multivar_epoch_50.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4995 - mae: 0.4545 - rmse: 0.7067 - mse: 0.4995 - val_loss: 0.4751 - val_mae: 0.4573 - val_rmse: 0.6893 - val_mse: 0.4751\n",
      "Epoch 51/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4995 - mae: 0.4547 - rmse: 0.7068 - mse: 0.4995\n",
      "Epoch 51: saving model to models\\preDecomp_multivar_epoch_51.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4995 - mae: 0.4548 - rmse: 0.7068 - mse: 0.4995 - val_loss: 0.4749 - val_mae: 0.4552 - val_rmse: 0.6891 - val_mse: 0.4749\n",
      "Epoch 52/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.4997 - mae: 0.4547 - rmse: 0.7069 - mse: 0.4997\n",
      "Epoch 52: saving model to models\\preDecomp_multivar_epoch_52.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4997 - mae: 0.4547 - rmse: 0.7069 - mse: 0.4997 - val_loss: 0.4767 - val_mae: 0.4607 - val_rmse: 0.6904 - val_mse: 0.4767\n",
      "Epoch 53/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.5001 - mae: 0.4552 - rmse: 0.7072 - mse: 0.5001\n",
      "Epoch 53: saving model to models\\preDecomp_multivar_epoch_53.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.5001 - mae: 0.4552 - rmse: 0.7072 - mse: 0.5001 - val_loss: 0.4761 - val_mae: 0.4604 - val_rmse: 0.6900 - val_mse: 0.4761\n",
      "Epoch 54/100\n",
      "2147/2155 [============================>.] - ETA: 0s - loss: 0.4992 - mae: 0.4538 - rmse: 0.7066 - mse: 0.4992\n",
      "Epoch 54: saving model to models\\preDecomp_multivar_epoch_54.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4986 - mae: 0.4536 - rmse: 0.7061 - mse: 0.4986 - val_loss: 0.4746 - val_mae: 0.4551 - val_rmse: 0.6889 - val_mse: 0.4746\n",
      "Epoch 55/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.4987 - mae: 0.4533 - rmse: 0.7062 - mse: 0.4987\n",
      "Epoch 55: saving model to models\\preDecomp_multivar_epoch_55.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4985 - mae: 0.4533 - rmse: 0.7060 - mse: 0.4985 - val_loss: 0.4741 - val_mae: 0.4559 - val_rmse: 0.6885 - val_mse: 0.4741\n",
      "Epoch 56/100\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.4984 - mae: 0.4532 - rmse: 0.7060 - mse: 0.4984\n",
      "Epoch 56: saving model to models\\preDecomp_multivar_epoch_56.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4984 - mae: 0.4532 - rmse: 0.7060 - mse: 0.4984 - val_loss: 0.4742 - val_mae: 0.4540 - val_rmse: 0.6886 - val_mse: 0.4742\n",
      "Epoch 57/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4988 - mae: 0.4531 - rmse: 0.7063 - mse: 0.4988\n",
      "Epoch 57: saving model to models\\preDecomp_multivar_epoch_57.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4985 - mae: 0.4531 - rmse: 0.7060 - mse: 0.4985 - val_loss: 0.4741 - val_mae: 0.4572 - val_rmse: 0.6886 - val_mse: 0.4741\n",
      "Epoch 58/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.4989 - mae: 0.4542 - rmse: 0.7063 - mse: 0.4989\n",
      "Epoch 58: saving model to models\\preDecomp_multivar_epoch_58.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4986 - mae: 0.4542 - rmse: 0.7061 - mse: 0.4986 - val_loss: 0.4746 - val_mae: 0.4567 - val_rmse: 0.6889 - val_mse: 0.4746\n",
      "Epoch 59/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4987 - mae: 0.4537 - rmse: 0.7062 - mse: 0.4987\n",
      "Epoch 59: saving model to models\\preDecomp_multivar_epoch_59.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4986 - mae: 0.4538 - rmse: 0.7061 - mse: 0.4986 - val_loss: 0.4755 - val_mae: 0.4534 - val_rmse: 0.6896 - val_mse: 0.4755\n",
      "Epoch 60/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.4996 - mae: 0.4546 - rmse: 0.7068 - mse: 0.4996\n",
      "Epoch 60: saving model to models\\preDecomp_multivar_epoch_60.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4994 - mae: 0.4546 - rmse: 0.7067 - mse: 0.4994 - val_loss: 0.4754 - val_mae: 0.4544 - val_rmse: 0.6895 - val_mse: 0.4754\n",
      "Epoch 61/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.4991 - mae: 0.4543 - rmse: 0.7065 - mse: 0.4991\n",
      "Epoch 61: saving model to models\\preDecomp_multivar_epoch_61.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4991 - mae: 0.4543 - rmse: 0.7065 - mse: 0.4991 - val_loss: 0.4754 - val_mae: 0.4560 - val_rmse: 0.6895 - val_mse: 0.4754\n",
      "Epoch 62/100\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.4998 - mae: 0.4547 - rmse: 0.7070 - mse: 0.4998\n",
      "Epoch 62: saving model to models\\preDecomp_multivar_epoch_62.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4996 - mae: 0.4547 - rmse: 0.7068 - mse: 0.4996 - val_loss: 0.4755 - val_mae: 0.4543 - val_rmse: 0.6896 - val_mse: 0.4755\n",
      "Epoch 63/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.5002 - mae: 0.4550 - rmse: 0.7073 - mse: 0.5002\n",
      "Epoch 63: saving model to models\\preDecomp_multivar_epoch_63.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4999 - mae: 0.4550 - rmse: 0.7070 - mse: 0.4999 - val_loss: 0.4759 - val_mae: 0.4554 - val_rmse: 0.6899 - val_mse: 0.4759\n",
      "Epoch 64/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.4999 - mae: 0.4550 - rmse: 0.7070 - mse: 0.4999\n",
      "Epoch 64: saving model to models\\preDecomp_multivar_epoch_64.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4997 - mae: 0.4550 - rmse: 0.7069 - mse: 0.4997 - val_loss: 0.4762 - val_mae: 0.4595 - val_rmse: 0.6900 - val_mse: 0.4762\n",
      "Epoch 65/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.5003 - mae: 0.4553 - rmse: 0.7073 - mse: 0.5003\n",
      "Epoch 65: saving model to models\\preDecomp_multivar_epoch_65.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.5000 - mae: 0.4553 - rmse: 0.7071 - mse: 0.5000 - val_loss: 0.4755 - val_mae: 0.4536 - val_rmse: 0.6895 - val_mse: 0.4755\n",
      "Epoch 66/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.4997 - mae: 0.4550 - rmse: 0.7069 - mse: 0.4997\n",
      "Epoch 66: saving model to models\\preDecomp_multivar_epoch_66.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4997 - mae: 0.4550 - rmse: 0.7069 - mse: 0.4997 - val_loss: 0.4756 - val_mae: 0.4535 - val_rmse: 0.6897 - val_mse: 0.4756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.4985 - mae: 0.4549 - rmse: 0.7061 - mse: 0.4985\n",
      "Epoch 67: saving model to models\\preDecomp_multivar_epoch_67.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4996 - mae: 0.4549 - rmse: 0.7068 - mse: 0.4996 - val_loss: 0.4751 - val_mae: 0.4580 - val_rmse: 0.6893 - val_mse: 0.4751\n",
      "Epoch 68/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.4997 - mae: 0.4550 - rmse: 0.7069 - mse: 0.4997\n",
      "Epoch 68: saving model to models\\preDecomp_multivar_epoch_68.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4995 - mae: 0.4550 - rmse: 0.7068 - mse: 0.4995 - val_loss: 0.4747 - val_mae: 0.4564 - val_rmse: 0.6890 - val_mse: 0.4747\n",
      "Epoch 69/100\n",
      "2147/2155 [============================>.] - ETA: 0s - loss: 0.4995 - mae: 0.4548 - rmse: 0.7067 - mse: 0.4995\n",
      "Epoch 69: saving model to models\\preDecomp_multivar_epoch_69.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4994 - mae: 0.4548 - rmse: 0.7067 - mse: 0.4994 - val_loss: 0.4753 - val_mae: 0.4545 - val_rmse: 0.6894 - val_mse: 0.4753\n",
      "Epoch 70/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.5005 - mae: 0.4552 - rmse: 0.7074 - mse: 0.5005\n",
      "Epoch 70: saving model to models\\preDecomp_multivar_epoch_70.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.5002 - mae: 0.4552 - rmse: 0.7073 - mse: 0.5002 - val_loss: 0.4757 - val_mae: 0.4574 - val_rmse: 0.6897 - val_mse: 0.4757\n",
      "Epoch 71/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.5001 - mae: 0.4553 - rmse: 0.7072 - mse: 0.5001\n",
      "Epoch 71: saving model to models\\preDecomp_multivar_epoch_71.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.5002 - mae: 0.4554 - rmse: 0.7072 - mse: 0.5002 - val_loss: 0.4767 - val_mae: 0.4598 - val_rmse: 0.6904 - val_mse: 0.4767\n",
      "Epoch 72/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.5000 - mae: 0.4551 - rmse: 0.7071 - mse: 0.5000\n",
      "Epoch 72: saving model to models\\preDecomp_multivar_epoch_72.h5\n",
      "2155/2155 [==============================] - 18s 8ms/step - loss: 0.4997 - mae: 0.4550 - rmse: 0.7069 - mse: 0.4997 - val_loss: 0.4749 - val_mae: 0.4557 - val_rmse: 0.6892 - val_mse: 0.4749\n",
      "Epoch 73/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.4993 - mae: 0.4544 - rmse: 0.7066 - mse: 0.4993\n",
      "Epoch 73: saving model to models\\preDecomp_multivar_epoch_73.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4991 - mae: 0.4543 - rmse: 0.7065 - mse: 0.4991 - val_loss: 0.4750 - val_mae: 0.4558 - val_rmse: 0.6892 - val_mse: 0.4750\n",
      "Epoch 74/100\n",
      "2147/2155 [============================>.] - ETA: 0s - loss: 0.4997 - mae: 0.4545 - rmse: 0.7069 - mse: 0.4997\n",
      "Epoch 74: saving model to models\\preDecomp_multivar_epoch_74.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4991 - mae: 0.4544 - rmse: 0.7065 - mse: 0.4991 - val_loss: 0.4750 - val_mae: 0.4552 - val_rmse: 0.6892 - val_mse: 0.4750\n",
      "Epoch 75/100\n",
      "2146/2155 [============================>.] - ETA: 0s - loss: 0.4974 - mae: 0.4539 - rmse: 0.7053 - mse: 0.4974\n",
      "Epoch 75: saving model to models\\preDecomp_multivar_epoch_75.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4988 - mae: 0.4540 - rmse: 0.7062 - mse: 0.4988 - val_loss: 0.4747 - val_mae: 0.4544 - val_rmse: 0.6890 - val_mse: 0.4747\n",
      "Epoch 76/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4989 - mae: 0.4540 - rmse: 0.7064 - mse: 0.4989\n",
      "Epoch 76: saving model to models\\preDecomp_multivar_epoch_76.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4987 - mae: 0.4540 - rmse: 0.7062 - mse: 0.4987 - val_loss: 0.4744 - val_mae: 0.4527 - val_rmse: 0.6887 - val_mse: 0.4744\n",
      "Epoch 77/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.4988 - mae: 0.4539 - rmse: 0.7062 - mse: 0.4988\n",
      "Epoch 77: saving model to models\\preDecomp_multivar_epoch_77.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4988 - mae: 0.4539 - rmse: 0.7062 - mse: 0.4988 - val_loss: 0.4749 - val_mae: 0.4580 - val_rmse: 0.6891 - val_mse: 0.4749\n",
      "Epoch 78/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.4987 - mae: 0.4536 - rmse: 0.7062 - mse: 0.4987\n",
      "Epoch 78: saving model to models\\preDecomp_multivar_epoch_78.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4986 - mae: 0.4537 - rmse: 0.7061 - mse: 0.4986 - val_loss: 0.4741 - val_mae: 0.4537 - val_rmse: 0.6885 - val_mse: 0.4741\n",
      "Epoch 79/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4991 - mae: 0.4539 - rmse: 0.7065 - mse: 0.4991\n",
      "Epoch 79: saving model to models\\preDecomp_multivar_epoch_79.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4987 - mae: 0.4538 - rmse: 0.7062 - mse: 0.4987 - val_loss: 0.4749 - val_mae: 0.4560 - val_rmse: 0.6891 - val_mse: 0.4749\n",
      "Epoch 80/100\n",
      "2147/2155 [============================>.] - ETA: 0s - loss: 0.5001 - mae: 0.4545 - rmse: 0.7071 - mse: 0.5001\n",
      "Epoch 80: saving model to models\\preDecomp_multivar_epoch_80.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4994 - mae: 0.4544 - rmse: 0.7066 - mse: 0.4994 - val_loss: 0.4752 - val_mae: 0.4543 - val_rmse: 0.6894 - val_mse: 0.4752\n",
      "Epoch 81/100\n",
      "2149/2155 [============================>.] - ETA: 0s - loss: 0.4991 - mae: 0.4538 - rmse: 0.7064 - mse: 0.4991\n",
      "Epoch 81: saving model to models\\preDecomp_multivar_epoch_81.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4989 - mae: 0.4539 - rmse: 0.7063 - mse: 0.4989 - val_loss: 0.4749 - val_mae: 0.4540 - val_rmse: 0.6891 - val_mse: 0.4749\n",
      "Epoch 82/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.4990 - mae: 0.4540 - rmse: 0.7064 - mse: 0.4990\n",
      "Epoch 82: saving model to models\\preDecomp_multivar_epoch_82.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4986 - mae: 0.4539 - rmse: 0.7061 - mse: 0.4986 - val_loss: 0.4743 - val_mae: 0.4548 - val_rmse: 0.6887 - val_mse: 0.4743\n",
      "Epoch 83/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4989 - mae: 0.4537 - rmse: 0.7063 - mse: 0.4989\n",
      "Epoch 83: saving model to models\\preDecomp_multivar_epoch_83.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4986 - mae: 0.4537 - rmse: 0.7061 - mse: 0.4986 - val_loss: 0.4744 - val_mae: 0.4547 - val_rmse: 0.6888 - val_mse: 0.4744\n",
      "Epoch 84/100\n",
      "2147/2155 [============================>.] - ETA: 0s - loss: 0.4986 - mae: 0.4535 - rmse: 0.7061 - mse: 0.4986\n",
      "Epoch 84: saving model to models\\preDecomp_multivar_epoch_84.h5\n",
      "2155/2155 [==============================] - 13s 6ms/step - loss: 0.4981 - mae: 0.4535 - rmse: 0.7058 - mse: 0.4981 - val_loss: 0.4741 - val_mae: 0.4557 - val_rmse: 0.6886 - val_mse: 0.4741\n",
      "Epoch 85/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.4983 - mae: 0.4533 - rmse: 0.7059 - mse: 0.4983\n",
      "Epoch 85: saving model to models\\preDecomp_multivar_epoch_85.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4982 - mae: 0.4533 - rmse: 0.7058 - mse: 0.4982 - val_loss: 0.4742 - val_mae: 0.4551 - val_rmse: 0.6886 - val_mse: 0.4742\n",
      "Epoch 86/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4986 - mae: 0.4533 - rmse: 0.7061 - mse: 0.4986\n",
      "Epoch 86: saving model to models\\preDecomp_multivar_epoch_86.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4982 - mae: 0.4533 - rmse: 0.7059 - mse: 0.4982 - val_loss: 0.4748 - val_mae: 0.4567 - val_rmse: 0.6891 - val_mse: 0.4748\n",
      "Epoch 87/100\n",
      "2151/2155 [============================>.] - ETA: 0s - loss: 0.4985 - mae: 0.4533 - rmse: 0.7061 - mse: 0.4985\n",
      "Epoch 87: saving model to models\\preDecomp_multivar_epoch_87.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4981 - mae: 0.4532 - rmse: 0.7058 - mse: 0.4981 - val_loss: 0.4744 - val_mae: 0.4531 - val_rmse: 0.6888 - val_mse: 0.4744\n",
      "Epoch 88/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4955 - mae: 0.4526 - rmse: 0.7039 - mse: 0.4955\n",
      "Epoch 88: saving model to models\\preDecomp_multivar_epoch_88.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4976 - mae: 0.4527 - rmse: 0.7054 - mse: 0.4976 - val_loss: 0.4749 - val_mae: 0.4586 - val_rmse: 0.6891 - val_mse: 0.4749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.4983 - mae: 0.4532 - rmse: 0.7059 - mse: 0.4983\n",
      "Epoch 89: saving model to models\\preDecomp_multivar_epoch_89.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4980 - mae: 0.4531 - rmse: 0.7057 - mse: 0.4980 - val_loss: 0.4749 - val_mae: 0.4578 - val_rmse: 0.6891 - val_mse: 0.4749\n",
      "Epoch 90/100\n",
      "2149/2155 [============================>.] - ETA: 0s - loss: 0.4977 - mae: 0.4533 - rmse: 0.7055 - mse: 0.4977\n",
      "Epoch 90: saving model to models\\preDecomp_multivar_epoch_90.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4981 - mae: 0.4532 - rmse: 0.7057 - mse: 0.4981 - val_loss: 0.4746 - val_mae: 0.4544 - val_rmse: 0.6889 - val_mse: 0.4746\n",
      "Epoch 91/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.4980 - mae: 0.4531 - rmse: 0.7057 - mse: 0.4980\n",
      "Epoch 91: saving model to models\\preDecomp_multivar_epoch_91.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4979 - mae: 0.4531 - rmse: 0.7056 - mse: 0.4979 - val_loss: 0.4753 - val_mae: 0.4562 - val_rmse: 0.6894 - val_mse: 0.4753\n",
      "Epoch 92/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.4948 - mae: 0.4539 - rmse: 0.7034 - mse: 0.4948\n",
      "Epoch 92: saving model to models\\preDecomp_multivar_epoch_92.h5\n",
      "2155/2155 [==============================] - 14s 6ms/step - loss: 0.4990 - mae: 0.4540 - rmse: 0.7064 - mse: 0.4990 - val_loss: 0.4743 - val_mae: 0.4555 - val_rmse: 0.6887 - val_mse: 0.4743\n",
      "Epoch 93/100\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.4984 - mae: 0.4539 - rmse: 0.7060 - mse: 0.4984\n",
      "Epoch 93: saving model to models\\preDecomp_multivar_epoch_93.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4984 - mae: 0.4539 - rmse: 0.7060 - mse: 0.4984 - val_loss: 0.4746 - val_mae: 0.4530 - val_rmse: 0.6889 - val_mse: 0.4746\n",
      "Epoch 94/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4988 - mae: 0.4538 - rmse: 0.7063 - mse: 0.4988\n",
      "Epoch 94: saving model to models\\preDecomp_multivar_epoch_94.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4985 - mae: 0.4538 - rmse: 0.7060 - mse: 0.4985 - val_loss: 0.4741 - val_mae: 0.4520 - val_rmse: 0.6886 - val_mse: 0.4741\n",
      "Epoch 95/100\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.4987 - mae: 0.4538 - rmse: 0.7062 - mse: 0.4987\n",
      "Epoch 95: saving model to models\\preDecomp_multivar_epoch_95.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4987 - mae: 0.4538 - rmse: 0.7062 - mse: 0.4987 - val_loss: 0.4755 - val_mae: 0.4565 - val_rmse: 0.6896 - val_mse: 0.4755\n",
      "Epoch 96/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4990 - mae: 0.4541 - rmse: 0.7064 - mse: 0.4990\n",
      "Epoch 96: saving model to models\\preDecomp_multivar_epoch_96.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4987 - mae: 0.4541 - rmse: 0.7062 - mse: 0.4987 - val_loss: 0.4755 - val_mae: 0.4560 - val_rmse: 0.6896 - val_mse: 0.4755\n",
      "Epoch 97/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4989 - mae: 0.4541 - rmse: 0.7063 - mse: 0.4989\n",
      "Epoch 97: saving model to models\\preDecomp_multivar_epoch_97.h5\n",
      "2155/2155 [==============================] - 14s 7ms/step - loss: 0.4988 - mae: 0.4541 - rmse: 0.7062 - mse: 0.4988 - val_loss: 0.4754 - val_mae: 0.4559 - val_rmse: 0.6895 - val_mse: 0.4754\n",
      "Epoch 98/100\n",
      "2150/2155 [============================>.] - ETA: 0s - loss: 0.4995 - mae: 0.4543 - rmse: 0.7067 - mse: 0.4995\n",
      "Epoch 98: saving model to models\\preDecomp_multivar_epoch_98.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4991 - mae: 0.4542 - rmse: 0.7065 - mse: 0.4991 - val_loss: 0.4756 - val_mae: 0.4575 - val_rmse: 0.6896 - val_mse: 0.4756\n",
      "Epoch 99/100\n",
      "2148/2155 [============================>.] - ETA: 0s - loss: 0.4992 - mae: 0.4541 - rmse: 0.7065 - mse: 0.4992\n",
      "Epoch 99: saving model to models\\preDecomp_multivar_epoch_99.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4989 - mae: 0.4542 - rmse: 0.7063 - mse: 0.4989 - val_loss: 0.4752 - val_mae: 0.4535 - val_rmse: 0.6893 - val_mse: 0.4752\n",
      "Epoch 100/100\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.4993 - mae: 0.4544 - rmse: 0.7066 - mse: 0.4993\n",
      "Epoch 100: saving model to models\\preDecomp_multivar_epoch_100.h5\n",
      "2155/2155 [==============================] - 15s 7ms/step - loss: 0.4992 - mae: 0.4544 - rmse: 0.7065 - mse: 0.4992 - val_loss: 0.4752 - val_mae: 0.4549 - val_rmse: 0.6894 - val_mse: 0.4752\n",
      "719/719 [==============================] - 2s 2ms/step - loss: 0.5900 - mae: 0.4591 - rmse: 0.7681 - mse: 0.5900\n",
      "Test RMSE = 0.77   |   MAE = 0.46\n"
     ]
    }
   ],
   "source": [
    "#  Create a checkpoint callback\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='models/preDecomp_multivar_epoch_{epoch:02d}.h5',\n",
    "    save_freq='epoch',                        # save after each epoch\n",
    "    save_weights_only=False,                  # save the entire model (architecture + weights + optimizer state)\n",
    "    verbose=1)\n",
    "\n",
    "history_before = model_before.fit(\n",
    "    ds_train_before,\n",
    "    epochs=100,\n",
    "    # Validation is used to determine if model is overfitting\n",
    "    validation_data=ds_val_before,\n",
    "    callbacks=[ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = model_before.evaluate(ds_test_before, return_dict=True)\n",
    "print(f\"Test RMSE = {results['rmse']:.2f}   |   MAE = {results['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aPhIh3THUT5I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPhIh3THUT5I",
    "outputId": "ba185ed0-e338-492d-db9f-c78820c321c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE  = 1520.90 (mg/dL)^2\n",
      "Test RMSE = 39.00 mg/dL\n",
      "Test MAE  = 23.31 mg/dL\n",
      "Test R^2 = 0.0096\n"
     ]
    }
   ],
   "source": [
    "y_pred_z = model_before.predict(ds_test_before, verbose=0).ravel()   # z-scores\n",
    "y_true_z = y_test_before\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred_before = y_pred_z * std_glu_before + mu_glu_before\n",
    "y_true_before = y_true_z * std_glu_before + mu_glu_before\n",
    "\n",
    "# metrics in true units\n",
    "mse  = np.mean((y_true - y_pred) ** 2)    \n",
    "rmse = np.sqrt(mse)\n",
    "mae  = np.mean(np.abs(y_true - y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Test MSE  = {mse :.2f} (mg/dL)^2\")\n",
    "print(f\"Test RMSE = {rmse:.2f} mg/dL\")\n",
    "print(f\"Test MAE  = {mae :.2f} mg/dL\")\n",
    "print(f\"Test R^2  = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886574b2",
   "metadata": {},
   "source": [
    "## Pre-Decompensation Classification Metrics\n",
    "\n",
    "Below we convert to classification metrics for the pre-decompensation model so we can compare to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5035ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical(y):\n",
    "    y_class = np.full((len(y)), \"unknown\", dtype='U10')\n",
    "    y_hypo_mask = y <= 70\n",
    "    y_hyper_mask = y >= 180\n",
    "    y_normal_mask = (y > 70) & (y < 180)\n",
    "    y_class[y_hypo_mask] = \"Hypo\"\n",
    "    y_class[y_hyper_mask] = \"Hyper\"\n",
    "    y_class[y_normal_mask] = \"Normal\"\n",
    "    return y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef061b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_z = model_before.predict(ds_test_before, verbose=0).ravel()   # z-scores\n",
    "y_true_z = y_test_before\n",
    "mu_glu_before, std_glu_before = SCALERS_BEFORE[1]          # index 1 is BG scale values\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred = y_pred_z * std_glu_before + mu_glu_before\n",
    "y_true = y_true_z * std_glu_before + mu_glu_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04f1948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = convert_categorical(y_pred)\n",
    "y_true_class = convert_categorical(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e14afd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_true_encoded = le.fit_transform(y_true_class)  # e.g. 'Hypo'=0, 'Normal'=1, 'Hyper'=2\n",
    "y_pred_encoded = le.transform(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f161ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Hyper       0.14      0.00      0.00      2097\n",
      "        Hypo       0.00      0.00      0.00       557\n",
      "      Normal       0.94      1.00      0.97     43311\n",
      "\n",
      "    accuracy                           0.94     45965\n",
      "   macro avg       0.36      0.33      0.32     45965\n",
      "weighted avg       0.89      0.94      0.91     45965\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    1     0  2096]\n",
      " [    0     0   557]\n",
      " [    6     0 43305]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mashal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Mashal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Mashal\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Full classification metrics\n",
    "print(classification_report(y_true_encoded, y_pred_encoded, target_names=le.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_encoded, y_pred_encoded)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5e11bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average AUC-ROC: 0.5001\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode\n",
    "y_true_bin = label_binarize(y_true_encoded, classes=[0,1,2])\n",
    "y_pred_bin = label_binarize(y_pred_encoded, classes=[0,1,2])\n",
    "\n",
    "# Macro-average AUC\n",
    "auc_macro = roc_auc_score(y_true_bin, y_pred_bin, average='macro', multi_class='ovo')\n",
    "print(f\"Macro-average AUC-ROC: {auc_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457ac8e0",
   "metadata": {},
   "source": [
    "### Pre-decompensation model extra testing\n",
    "\n",
    "Below we test the pre-decompensation model on the full dataset. The testing variables that are loaded via pickle are created by the \"Multivariate Resampled LSTM Model.ipynb\" file in the GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44d9c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'Pickles/filtered_glu_test.pkl.gz'\n",
    "with gzip.open(test_path, 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "X_test = test_data['X_test']\n",
    "y_test = test_data['y_test']\n",
    "\n",
    "train_path = 'Pickles/filtered_glu_train.pkl.gz'\n",
    "with gzip.open(train_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "SCALERS  = train_data['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4ae2d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test  = make_ds(X_test,  y_test,  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8340a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE  = 2210.36 (mg/dL)^2\n",
      "Test RMSE = 47.01 mg/dL\n",
      "Test MAE  = 31.08 mg/dL\n",
      "Test R^2  = 0.0094\n"
     ]
    }
   ],
   "source": [
    "y_pred_z = model_before.predict(ds_test, verbose=0).ravel()   # z-scores\n",
    "y_true_z = y_test\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred_all = y_pred_z * std_glu_before + mu_glu_before\n",
    "y_true_all= y_true_z * std_glu_before + mu_glu_before\n",
    "\n",
    "# metrics in true units\n",
    "mse  = np.mean((y_true_all - y_pred_all) ** 2)    \n",
    "rmse = np.sqrt(mse)\n",
    "mae  = np.mean(np.abs(y_true_all - y_pred_all))\n",
    "r2 = r2_score(y_true_all, y_pred_all)\n",
    "\n",
    "print(f\"Test MSE  = {mse :.2f} (mg/dL)^2\")\n",
    "print(f\"Test RMSE = {rmse:.2f} mg/dL\")\n",
    "print(f\"Test MAE  = {mae :.2f} mg/dL\")\n",
    "print(f\"Test R^2  = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1f5b3",
   "metadata": {},
   "source": [
    "We can see this model performs much better than the multivariate model in \"Multivariate Resampled LSTM Model.ipynb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2986ee9a",
   "metadata": {},
   "source": [
    "#### Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c96a5981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Hyper       0.46      0.00      0.00      9470\n",
      "        Hypo       0.00      0.00      0.00      1299\n",
      "      Normal       0.87      1.00      0.93     73994\n",
      "\n",
      "    accuracy                           0.87     84763\n",
      "   macro avg       0.44      0.33      0.31     84763\n",
      "weighted avg       0.81      0.87      0.81     84763\n",
      "\n",
      "Confusion Matrix:\n",
      " [[    6     0  9464]\n",
      " [    0     0  1299]\n",
      " [    7     1 73986]]\n",
      "\n",
      "Macro-average AUC-ROC: 0.5002\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = convert_categorical(y_pred_all)\n",
    "y_true_class = convert_categorical(y_true_all)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_true_encoded = le.fit_transform(y_true_class)  # e.g. 'Hypo'=0, 'Normal'=1, 'Hyper'=2\n",
    "y_pred_encoded = le.transform(y_pred_class)\n",
    "\n",
    "# Full classification metrics\n",
    "print(classification_report(y_true_encoded, y_pred_encoded, target_names=le.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_encoded, y_pred_encoded)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# One-hot encode\n",
    "y_true_bin = label_binarize(y_true_encoded, classes=[0,1,2])\n",
    "y_pred_bin = label_binarize(y_pred_encoded, classes=[0,1,2])\n",
    "\n",
    "# Macro-average AUC\n",
    "auc_macro = roc_auc_score(y_true_bin, y_pred_bin, average='macro', multi_class='ovo')\n",
    "print(f\"\\nMacro-average AUC-ROC: {auc_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37443d9",
   "metadata": {},
   "source": [
    "# Post-decompensation LSTM model\n",
    "\n",
    "Below here we train a LSTM model using data from after a patient's first decompensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24a678aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "27DSFKlALWUJ",
    "outputId": "7a85fc99-c884-4c41-82e2-f0248ab6c99e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking_1 (Masking)         (None, 6, 10)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                19200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,313\n",
      "Trainable params: 21,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_after = tf.keras.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=SENTINEL, input_shape=(L, F)),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    # A dense layer here is necessary, as each hidden state output, which is\n",
    "    # the output of an LSTM unit is only within the range of a tanh activation function,\n",
    "    # so further transformation is needed\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)                   # regression\n",
    "])\n",
    "\n",
    "model_after.compile(loss='mse', optimizer='adam', metrics=['mae', RootMeanSquaredError(name='rmse'), 'mse'])\n",
    "model_after.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ed77c59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfy1ukOPLYTR",
    "outputId": "7e65fdc0-b857-4785-c00f-661b0207ed1c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8670 - mae: 0.6629 - rmse: 0.9311 - mse: 0.8670\n",
      "Epoch 1: saving model to models\\postDecomp_multivar_epoch_01.h5\n",
      "4539/4539 [==============================] - 61s 13ms/step - loss: 0.8669 - mae: 0.6629 - rmse: 0.9311 - mse: 0.8669 - val_loss: 0.8925 - val_mae: 0.6687 - val_rmse: 0.9447 - val_mse: 0.8925\n",
      "Epoch 2/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8586 - mae: 0.6589 - rmse: 0.9266 - mse: 0.8586\n",
      "Epoch 2: saving model to models\\postDecomp_multivar_epoch_02.h5\n",
      "4539/4539 [==============================] - 62s 14ms/step - loss: 0.8586 - mae: 0.6589 - rmse: 0.9266 - mse: 0.8586 - val_loss: 0.8953 - val_mae: 0.6736 - val_rmse: 0.9462 - val_mse: 0.8953\n",
      "Epoch 3/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8615 - mae: 0.6607 - rmse: 0.9282 - mse: 0.8615\n",
      "Epoch 3: saving model to models\\postDecomp_multivar_epoch_03.h5\n",
      "4539/4539 [==============================] - 56s 12ms/step - loss: 0.8615 - mae: 0.6607 - rmse: 0.9282 - mse: 0.8615 - val_loss: 0.9036 - val_mae: 0.6762 - val_rmse: 0.9506 - val_mse: 0.9036\n",
      "Epoch 4/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8562 - mae: 0.6579 - rmse: 0.9253 - mse: 0.8562\n",
      "Epoch 4: saving model to models\\postDecomp_multivar_epoch_04.h5\n",
      "4539/4539 [==============================] - 62s 14ms/step - loss: 0.8562 - mae: 0.6579 - rmse: 0.9253 - mse: 0.8562 - val_loss: 0.8893 - val_mae: 0.6556 - val_rmse: 0.9430 - val_mse: 0.8893\n",
      "Epoch 5/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8531 - mae: 0.6564 - rmse: 0.9236 - mse: 0.8531\n",
      "Epoch 5: saving model to models\\postDecomp_multivar_epoch_05.h5\n",
      "4539/4539 [==============================] - 59s 13ms/step - loss: 0.8531 - mae: 0.6564 - rmse: 0.9236 - mse: 0.8531 - val_loss: 0.8888 - val_mae: 0.6700 - val_rmse: 0.9428 - val_mse: 0.8888\n",
      "Epoch 6/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8545 - mae: 0.6573 - rmse: 0.9244 - mse: 0.8545\n",
      "Epoch 6: saving model to models\\postDecomp_multivar_epoch_06.h5\n",
      "4539/4539 [==============================] - 55s 12ms/step - loss: 0.8544 - mae: 0.6573 - rmse: 0.9244 - mse: 0.8544 - val_loss: 0.8902 - val_mae: 0.6591 - val_rmse: 0.9435 - val_mse: 0.8902\n",
      "Epoch 7/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8571 - mae: 0.6581 - rmse: 0.9258 - mse: 0.8571\n",
      "Epoch 7: saving model to models\\postDecomp_multivar_epoch_07.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8571 - mae: 0.6581 - rmse: 0.9258 - mse: 0.8571 - val_loss: 0.9023 - val_mae: 0.6655 - val_rmse: 0.9499 - val_mse: 0.9023\n",
      "Epoch 8/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8641 - mae: 0.6621 - rmse: 0.9296 - mse: 0.8641\n",
      "Epoch 8: saving model to models\\postDecomp_multivar_epoch_08.h5\n",
      "4539/4539 [==============================] - 59s 13ms/step - loss: 0.8641 - mae: 0.6621 - rmse: 0.9296 - mse: 0.8641 - val_loss: 0.9008 - val_mae: 0.6761 - val_rmse: 0.9491 - val_mse: 0.9008\n",
      "Epoch 9/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8544 - mae: 0.6568 - rmse: 0.9243 - mse: 0.8544\n",
      "Epoch 9: saving model to models\\postDecomp_multivar_epoch_09.h5\n",
      "4539/4539 [==============================] - 59s 13ms/step - loss: 0.8543 - mae: 0.6568 - rmse: 0.9243 - mse: 0.8543 - val_loss: 0.8892 - val_mae: 0.6607 - val_rmse: 0.9430 - val_mse: 0.8892\n",
      "Epoch 10/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8523 - mae: 0.6559 - rmse: 0.9232 - mse: 0.8523\n",
      "Epoch 10: saving model to models\\postDecomp_multivar_epoch_10.h5\n",
      "4539/4539 [==============================] - 59s 13ms/step - loss: 0.8522 - mae: 0.6559 - rmse: 0.9231 - mse: 0.8522 - val_loss: 0.8901 - val_mae: 0.6673 - val_rmse: 0.9435 - val_mse: 0.8901\n",
      "Epoch 11/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8532 - mae: 0.6564 - rmse: 0.9237 - mse: 0.8532\n",
      "Epoch 11: saving model to models\\postDecomp_multivar_epoch_11.h5\n",
      "4539/4539 [==============================] - 58s 13ms/step - loss: 0.8532 - mae: 0.6564 - rmse: 0.9237 - mse: 0.8532 - val_loss: 0.8928 - val_mae: 0.6639 - val_rmse: 0.9449 - val_mse: 0.8928\n",
      "Epoch 12/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8518 - mae: 0.6561 - rmse: 0.9229 - mse: 0.8518\n",
      "Epoch 12: saving model to models\\postDecomp_multivar_epoch_12.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8518 - mae: 0.6561 - rmse: 0.9229 - mse: 0.8518 - val_loss: 0.8909 - val_mae: 0.6666 - val_rmse: 0.9439 - val_mse: 0.8909\n",
      "Epoch 13/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8479 - mae: 0.6537 - rmse: 0.9208 - mse: 0.8479\n",
      "Epoch 13: saving model to models\\postDecomp_multivar_epoch_13.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8481 - mae: 0.6537 - rmse: 0.9209 - mse: 0.8481 - val_loss: 0.8835 - val_mae: 0.6646 - val_rmse: 0.9399 - val_mse: 0.8835\n",
      "Epoch 14/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8461 - mae: 0.6524 - rmse: 0.9199 - mse: 0.8461\n",
      "Epoch 14: saving model to models\\postDecomp_multivar_epoch_14.h5\n",
      "4539/4539 [==============================] - 59s 13ms/step - loss: 0.8462 - mae: 0.6524 - rmse: 0.9199 - mse: 0.8462 - val_loss: 0.8835 - val_mae: 0.6651 - val_rmse: 0.9399 - val_mse: 0.8835\n",
      "Epoch 15/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8470 - mae: 0.6531 - rmse: 0.9203 - mse: 0.8470\n",
      "Epoch 15: saving model to models\\postDecomp_multivar_epoch_15.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8469 - mae: 0.6531 - rmse: 0.9203 - mse: 0.8469 - val_loss: 0.8833 - val_mae: 0.6666 - val_rmse: 0.9398 - val_mse: 0.8833\n",
      "Epoch 16/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8457 - mae: 0.6521 - rmse: 0.9196 - mse: 0.8457\n",
      "Epoch 16: saving model to models\\postDecomp_multivar_epoch_16.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8456 - mae: 0.6520 - rmse: 0.9196 - mse: 0.8456 - val_loss: 0.8818 - val_mae: 0.6594 - val_rmse: 0.9391 - val_mse: 0.8818\n",
      "Epoch 17/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8446 - mae: 0.6515 - rmse: 0.9190 - mse: 0.8446\n",
      "Epoch 17: saving model to models\\postDecomp_multivar_epoch_17.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8446 - mae: 0.6515 - rmse: 0.9190 - mse: 0.8446 - val_loss: 0.8890 - val_mae: 0.6493 - val_rmse: 0.9429 - val_mse: 0.8890\n",
      "Epoch 18/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8439 - mae: 0.6514 - rmse: 0.9187 - mse: 0.8439\n",
      "Epoch 18: saving model to models\\postDecomp_multivar_epoch_18.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8440 - mae: 0.6514 - rmse: 0.9187 - mse: 0.8440 - val_loss: 0.8817 - val_mae: 0.6659 - val_rmse: 0.9390 - val_mse: 0.8817\n",
      "Epoch 19/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8447 - mae: 0.6517 - rmse: 0.9191 - mse: 0.8447\n",
      "Epoch 19: saving model to models\\postDecomp_multivar_epoch_19.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8447 - mae: 0.6518 - rmse: 0.9191 - mse: 0.8447 - val_loss: 0.8840 - val_mae: 0.6655 - val_rmse: 0.9402 - val_mse: 0.8840\n",
      "Epoch 20/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8482 - mae: 0.6541 - rmse: 0.9210 - mse: 0.8482\n",
      "Epoch 20: saving model to models\\postDecomp_multivar_epoch_20.h5\n",
      "4539/4539 [==============================] - 135s 30ms/step - loss: 0.8485 - mae: 0.6541 - rmse: 0.9212 - mse: 0.8485 - val_loss: 0.8898 - val_mae: 0.6669 - val_rmse: 0.9433 - val_mse: 0.8898\n",
      "Epoch 21/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8523 - mae: 0.6560 - rmse: 0.9232 - mse: 0.8523\n",
      "Epoch 21: saving model to models\\postDecomp_multivar_epoch_21.h5\n",
      "4539/4539 [==============================] - 67s 15ms/step - loss: 0.8523 - mae: 0.6560 - rmse: 0.9232 - mse: 0.8523 - val_loss: 0.8908 - val_mae: 0.6633 - val_rmse: 0.9438 - val_mse: 0.8908\n",
      "Epoch 22/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8513 - mae: 0.6558 - rmse: 0.9226 - mse: 0.8513\n",
      "Epoch 22: saving model to models\\postDecomp_multivar_epoch_22.h5\n",
      "4539/4539 [==============================] - 61s 13ms/step - loss: 0.8513 - mae: 0.6558 - rmse: 0.9227 - mse: 0.8513 - val_loss: 0.8875 - val_mae: 0.6644 - val_rmse: 0.9421 - val_mse: 0.8875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8483 - mae: 0.6546 - rmse: 0.9210 - mse: 0.8483\n",
      "Epoch 23: saving model to models\\postDecomp_multivar_epoch_23.h5\n",
      "4539/4539 [==============================] - 60s 13ms/step - loss: 0.8483 - mae: 0.6545 - rmse: 0.9210 - mse: 0.8483 - val_loss: 0.8878 - val_mae: 0.6654 - val_rmse: 0.9422 - val_mse: 0.8878\n",
      "Epoch 24/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8480 - mae: 0.6542 - rmse: 0.9209 - mse: 0.8480\n",
      "Epoch 24: saving model to models\\postDecomp_multivar_epoch_24.h5\n",
      "4539/4539 [==============================] - 61s 13ms/step - loss: 0.8482 - mae: 0.6543 - rmse: 0.9210 - mse: 0.8482 - val_loss: 0.8869 - val_mae: 0.6613 - val_rmse: 0.9418 - val_mse: 0.8869\n",
      "Epoch 25/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8485 - mae: 0.6543 - rmse: 0.9212 - mse: 0.8485\n",
      "Epoch 25: saving model to models\\postDecomp_multivar_epoch_25.h5\n",
      "4539/4539 [==============================] - 61s 13ms/step - loss: 0.8485 - mae: 0.6543 - rmse: 0.9211 - mse: 0.8485 - val_loss: 0.8886 - val_mae: 0.6582 - val_rmse: 0.9426 - val_mse: 0.8886\n",
      "Epoch 26/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8482 - mae: 0.6541 - rmse: 0.9210 - mse: 0.8482\n",
      "Epoch 26: saving model to models\\postDecomp_multivar_epoch_26.h5\n",
      "4539/4539 [==============================] - 62s 14ms/step - loss: 0.8480 - mae: 0.6541 - rmse: 0.9209 - mse: 0.8480 - val_loss: 0.8855 - val_mae: 0.6635 - val_rmse: 0.9410 - val_mse: 0.8855\n",
      "Epoch 27/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8479 - mae: 0.6541 - rmse: 0.9208 - mse: 0.8479\n",
      "Epoch 27: saving model to models\\postDecomp_multivar_epoch_27.h5\n",
      "4539/4539 [==============================] - 62s 14ms/step - loss: 0.8478 - mae: 0.6541 - rmse: 0.9208 - mse: 0.8478 - val_loss: 0.8881 - val_mae: 0.6615 - val_rmse: 0.9424 - val_mse: 0.8881\n",
      "Epoch 28/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8480 - mae: 0.6542 - rmse: 0.9209 - mse: 0.8480\n",
      "Epoch 28: saving model to models\\postDecomp_multivar_epoch_28.h5\n",
      "4539/4539 [==============================] - 63s 14ms/step - loss: 0.8481 - mae: 0.6542 - rmse: 0.9209 - mse: 0.8481 - val_loss: 0.8897 - val_mae: 0.6585 - val_rmse: 0.9433 - val_mse: 0.8897\n",
      "Epoch 29/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8493 - mae: 0.6552 - rmse: 0.9216 - mse: 0.8493\n",
      "Epoch 29: saving model to models\\postDecomp_multivar_epoch_29.h5\n",
      "4539/4539 [==============================] - 63s 14ms/step - loss: 0.8494 - mae: 0.6552 - rmse: 0.9216 - mse: 0.8494 - val_loss: 0.8883 - val_mae: 0.6671 - val_rmse: 0.9425 - val_mse: 0.8883\n",
      "Epoch 30/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8476 - mae: 0.6536 - rmse: 0.9207 - mse: 0.8476\n",
      "Epoch 30: saving model to models\\postDecomp_multivar_epoch_30.h5\n",
      "4539/4539 [==============================] - 63s 14ms/step - loss: 0.8477 - mae: 0.6536 - rmse: 0.9207 - mse: 0.8477 - val_loss: 0.8913 - val_mae: 0.6563 - val_rmse: 0.9441 - val_mse: 0.8913\n",
      "Epoch 31/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8460 - mae: 0.6534 - rmse: 0.9198 - mse: 0.8460\n",
      "Epoch 31: saving model to models\\postDecomp_multivar_epoch_31.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8474 - mae: 0.6535 - rmse: 0.9205 - mse: 0.8474 - val_loss: 0.8884 - val_mae: 0.6594 - val_rmse: 0.9425 - val_mse: 0.8884\n",
      "Epoch 32/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8471 - mae: 0.6531 - rmse: 0.9204 - mse: 0.8471\n",
      "Epoch 32: saving model to models\\postDecomp_multivar_epoch_32.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8471 - mae: 0.6531 - rmse: 0.9204 - mse: 0.8471 - val_loss: 0.8868 - val_mae: 0.6580 - val_rmse: 0.9417 - val_mse: 0.8868\n",
      "Epoch 33/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8460 - mae: 0.6527 - rmse: 0.9198 - mse: 0.8460\n",
      "Epoch 33: saving model to models\\postDecomp_multivar_epoch_33.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8460 - mae: 0.6527 - rmse: 0.9198 - mse: 0.8460 - val_loss: 0.8845 - val_mae: 0.6630 - val_rmse: 0.9405 - val_mse: 0.8845\n",
      "Epoch 34/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8455 - mae: 0.6523 - rmse: 0.9195 - mse: 0.8455\n",
      "Epoch 34: saving model to models\\postDecomp_multivar_epoch_34.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8455 - mae: 0.6523 - rmse: 0.9195 - mse: 0.8455 - val_loss: 0.8893 - val_mae: 0.6544 - val_rmse: 0.9430 - val_mse: 0.8893\n",
      "Epoch 35/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8470 - mae: 0.6530 - rmse: 0.9203 - mse: 0.8470\n",
      "Epoch 35: saving model to models\\postDecomp_multivar_epoch_35.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8470 - mae: 0.6530 - rmse: 0.9203 - mse: 0.8470 - val_loss: 0.8871 - val_mae: 0.6580 - val_rmse: 0.9419 - val_mse: 0.8871\n",
      "Epoch 36/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8467 - mae: 0.6526 - rmse: 0.9202 - mse: 0.8467\n",
      "Epoch 36: saving model to models\\postDecomp_multivar_epoch_36.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8467 - mae: 0.6526 - rmse: 0.9201 - mse: 0.8467 - val_loss: 0.8877 - val_mae: 0.6636 - val_rmse: 0.9422 - val_mse: 0.8877\n",
      "Epoch 37/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8472 - mae: 0.6532 - rmse: 0.9204 - mse: 0.8472\n",
      "Epoch 37: saving model to models\\postDecomp_multivar_epoch_37.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8471 - mae: 0.6532 - rmse: 0.9204 - mse: 0.8471 - val_loss: 0.8861 - val_mae: 0.6617 - val_rmse: 0.9413 - val_mse: 0.8861\n",
      "Epoch 38/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8458 - mae: 0.6525 - rmse: 0.9197 - mse: 0.8458\n",
      "Epoch 38: saving model to models\\postDecomp_multivar_epoch_38.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8459 - mae: 0.6525 - rmse: 0.9197 - mse: 0.8459 - val_loss: 0.8864 - val_mae: 0.6654 - val_rmse: 0.9415 - val_mse: 0.8864\n",
      "Epoch 39/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8462 - mae: 0.6528 - rmse: 0.9199 - mse: 0.8462\n",
      "Epoch 39: saving model to models\\postDecomp_multivar_epoch_39.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8463 - mae: 0.6528 - rmse: 0.9200 - mse: 0.8463 - val_loss: 0.8871 - val_mae: 0.6567 - val_rmse: 0.9419 - val_mse: 0.8871\n",
      "Epoch 40/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8459 - mae: 0.6524 - rmse: 0.9197 - mse: 0.8459\n",
      "Epoch 40: saving model to models\\postDecomp_multivar_epoch_40.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8458 - mae: 0.6523 - rmse: 0.9197 - mse: 0.8458 - val_loss: 0.8874 - val_mae: 0.6547 - val_rmse: 0.9420 - val_mse: 0.8874\n",
      "Epoch 41/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8447 - mae: 0.6521 - rmse: 0.9191 - mse: 0.8447\n",
      "Epoch 41: saving model to models\\postDecomp_multivar_epoch_41.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8447 - mae: 0.6521 - rmse: 0.9191 - mse: 0.8447 - val_loss: 0.8826 - val_mae: 0.6609 - val_rmse: 0.9395 - val_mse: 0.8826\n",
      "Epoch 42/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8437 - mae: 0.6514 - rmse: 0.9185 - mse: 0.8437\n",
      "Epoch 42: saving model to models\\postDecomp_multivar_epoch_42.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8437 - mae: 0.6514 - rmse: 0.9185 - mse: 0.8437 - val_loss: 0.8861 - val_mae: 0.6538 - val_rmse: 0.9413 - val_mse: 0.8861\n",
      "Epoch 43/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8431 - mae: 0.6513 - rmse: 0.9182 - mse: 0.8431\n",
      "Epoch 43: saving model to models\\postDecomp_multivar_epoch_43.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8431 - mae: 0.6514 - rmse: 0.9182 - mse: 0.8431 - val_loss: 0.8832 - val_mae: 0.6594 - val_rmse: 0.9398 - val_mse: 0.8832\n",
      "Epoch 44/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8437 - mae: 0.6517 - rmse: 0.9186 - mse: 0.8437\n",
      "Epoch 44: saving model to models\\postDecomp_multivar_epoch_44.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8437 - mae: 0.6517 - rmse: 0.9185 - mse: 0.8437 - val_loss: 0.8843 - val_mae: 0.6622 - val_rmse: 0.9404 - val_mse: 0.8843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8446 - mae: 0.6519 - rmse: 0.9190 - mse: 0.8446\n",
      "Epoch 45: saving model to models\\postDecomp_multivar_epoch_45.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8446 - mae: 0.6519 - rmse: 0.9190 - mse: 0.8446 - val_loss: 0.8840 - val_mae: 0.6580 - val_rmse: 0.9402 - val_mse: 0.8840\n",
      "Epoch 46/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8436 - mae: 0.6515 - rmse: 0.9185 - mse: 0.8436\n",
      "Epoch 46: saving model to models\\postDecomp_multivar_epoch_46.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8436 - mae: 0.6515 - rmse: 0.9185 - mse: 0.8436 - val_loss: 0.8830 - val_mae: 0.6572 - val_rmse: 0.9397 - val_mse: 0.8830\n",
      "Epoch 47/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8428 - mae: 0.6508 - rmse: 0.9181 - mse: 0.8428\n",
      "Epoch 47: saving model to models\\postDecomp_multivar_epoch_47.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8428 - mae: 0.6508 - rmse: 0.9180 - mse: 0.8428 - val_loss: 0.8838 - val_mae: 0.6709 - val_rmse: 0.9401 - val_mse: 0.8838\n",
      "Epoch 48/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8440 - mae: 0.6518 - rmse: 0.9187 - mse: 0.8440\n",
      "Epoch 48: saving model to models\\postDecomp_multivar_epoch_48.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8440 - mae: 0.6518 - rmse: 0.9187 - mse: 0.8440 - val_loss: 0.8885 - val_mae: 0.6635 - val_rmse: 0.9426 - val_mse: 0.8885\n",
      "Epoch 49/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8445 - mae: 0.6519 - rmse: 0.9190 - mse: 0.8445\n",
      "Epoch 49: saving model to models\\postDecomp_multivar_epoch_49.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8445 - mae: 0.6519 - rmse: 0.9190 - mse: 0.8445 - val_loss: 0.8864 - val_mae: 0.6582 - val_rmse: 0.9415 - val_mse: 0.8864\n",
      "Epoch 50/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8437 - mae: 0.6517 - rmse: 0.9186 - mse: 0.8437\n",
      "Epoch 50: saving model to models\\postDecomp_multivar_epoch_50.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8437 - mae: 0.6517 - rmse: 0.9185 - mse: 0.8437 - val_loss: 0.8842 - val_mae: 0.6655 - val_rmse: 0.9403 - val_mse: 0.8842\n",
      "Epoch 51/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8429 - mae: 0.6513 - rmse: 0.9181 - mse: 0.8429\n",
      "Epoch 51: saving model to models\\postDecomp_multivar_epoch_51.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8430 - mae: 0.6513 - rmse: 0.9181 - mse: 0.8430 - val_loss: 0.8839 - val_mae: 0.6618 - val_rmse: 0.9402 - val_mse: 0.8839\n",
      "Epoch 52/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8430 - mae: 0.6513 - rmse: 0.9182 - mse: 0.8430\n",
      "Epoch 52: saving model to models\\postDecomp_multivar_epoch_52.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8430 - mae: 0.6513 - rmse: 0.9181 - mse: 0.8430 - val_loss: 0.8852 - val_mae: 0.6654 - val_rmse: 0.9409 - val_mse: 0.8852\n",
      "Epoch 53/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8429 - mae: 0.6513 - rmse: 0.9181 - mse: 0.8429\n",
      "Epoch 53: saving model to models\\postDecomp_multivar_epoch_53.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8429 - mae: 0.6513 - rmse: 0.9181 - mse: 0.8429 - val_loss: 0.8844 - val_mae: 0.6662 - val_rmse: 0.9404 - val_mse: 0.8844\n",
      "Epoch 54/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8421 - mae: 0.6511 - rmse: 0.9177 - mse: 0.8421\n",
      "Epoch 54: saving model to models\\postDecomp_multivar_epoch_54.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8423 - mae: 0.6512 - rmse: 0.9177 - mse: 0.8423 - val_loss: 0.8845 - val_mae: 0.6641 - val_rmse: 0.9405 - val_mse: 0.8845\n",
      "Epoch 55/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8429 - mae: 0.6513 - rmse: 0.9181 - mse: 0.8429\n",
      "Epoch 55: saving model to models\\postDecomp_multivar_epoch_55.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8432 - mae: 0.6514 - rmse: 0.9182 - mse: 0.8432 - val_loss: 0.8837 - val_mae: 0.6606 - val_rmse: 0.9400 - val_mse: 0.8837\n",
      "Epoch 56/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8432 - mae: 0.6514 - rmse: 0.9183 - mse: 0.8432\n",
      "Epoch 56: saving model to models\\postDecomp_multivar_epoch_56.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8434 - mae: 0.6515 - rmse: 0.9183 - mse: 0.8434 - val_loss: 0.8851 - val_mae: 0.6658 - val_rmse: 0.9408 - val_mse: 0.8851\n",
      "Epoch 57/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8420 - mae: 0.6508 - rmse: 0.9176 - mse: 0.8420\n",
      "Epoch 57: saving model to models\\postDecomp_multivar_epoch_57.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8419 - mae: 0.6508 - rmse: 0.9176 - mse: 0.8419 - val_loss: 0.8818 - val_mae: 0.6589 - val_rmse: 0.9391 - val_mse: 0.8818\n",
      "Epoch 58/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8414 - mae: 0.6504 - rmse: 0.9173 - mse: 0.8414\n",
      "Epoch 58: saving model to models\\postDecomp_multivar_epoch_58.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8414 - mae: 0.6504 - rmse: 0.9173 - mse: 0.8414 - val_loss: 0.8824 - val_mae: 0.6617 - val_rmse: 0.9394 - val_mse: 0.8824\n",
      "Epoch 59/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8422 - mae: 0.6508 - rmse: 0.9177 - mse: 0.8422\n",
      "Epoch 59: saving model to models\\postDecomp_multivar_epoch_59.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8422 - mae: 0.6509 - rmse: 0.9177 - mse: 0.8422 - val_loss: 0.8840 - val_mae: 0.6571 - val_rmse: 0.9402 - val_mse: 0.8840\n",
      "Epoch 60/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8429 - mae: 0.6512 - rmse: 0.9181 - mse: 0.8429\n",
      "Epoch 60: saving model to models\\postDecomp_multivar_epoch_60.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8429 - mae: 0.6512 - rmse: 0.9181 - mse: 0.8429 - val_loss: 0.8824 - val_mae: 0.6603 - val_rmse: 0.9394 - val_mse: 0.8824\n",
      "Epoch 61/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8413 - mae: 0.6505 - rmse: 0.9172 - mse: 0.8413\n",
      "Epoch 61: saving model to models\\postDecomp_multivar_epoch_61.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8414 - mae: 0.6506 - rmse: 0.9173 - mse: 0.8414 - val_loss: 0.8860 - val_mae: 0.6746 - val_rmse: 0.9413 - val_mse: 0.8860\n",
      "Epoch 62/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8416 - mae: 0.6504 - rmse: 0.9174 - mse: 0.8416\n",
      "Epoch 62: saving model to models\\postDecomp_multivar_epoch_62.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8415 - mae: 0.6504 - rmse: 0.9173 - mse: 0.8415 - val_loss: 0.8840 - val_mae: 0.6509 - val_rmse: 0.9402 - val_mse: 0.8840\n",
      "Epoch 63/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8407 - mae: 0.6500 - rmse: 0.9169 - mse: 0.8407\n",
      "Epoch 63: saving model to models\\postDecomp_multivar_epoch_63.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8407 - mae: 0.6500 - rmse: 0.9169 - mse: 0.8407 - val_loss: 0.8825 - val_mae: 0.6524 - val_rmse: 0.9394 - val_mse: 0.8825\n",
      "Epoch 64/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8416 - mae: 0.6505 - rmse: 0.9174 - mse: 0.8416\n",
      "Epoch 64: saving model to models\\postDecomp_multivar_epoch_64.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8416 - mae: 0.6505 - rmse: 0.9174 - mse: 0.8416 - val_loss: 0.8812 - val_mae: 0.6605 - val_rmse: 0.9387 - val_mse: 0.8812\n",
      "Epoch 65/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8418 - mae: 0.6507 - rmse: 0.9175 - mse: 0.8418\n",
      "Epoch 65: saving model to models\\postDecomp_multivar_epoch_65.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8418 - mae: 0.6507 - rmse: 0.9175 - mse: 0.8418 - val_loss: 0.8822 - val_mae: 0.6625 - val_rmse: 0.9393 - val_mse: 0.8822\n",
      "Epoch 66/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8415 - mae: 0.6508 - rmse: 0.9173 - mse: 0.8415\n",
      "Epoch 66: saving model to models\\postDecomp_multivar_epoch_66.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8414 - mae: 0.6507 - rmse: 0.9173 - mse: 0.8414 - val_loss: 0.8801 - val_mae: 0.6576 - val_rmse: 0.9381 - val_mse: 0.8801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8417 - mae: 0.6505 - rmse: 0.9175 - mse: 0.8417\n",
      "Epoch 67: saving model to models\\postDecomp_multivar_epoch_67.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8417 - mae: 0.6505 - rmse: 0.9174 - mse: 0.8417 - val_loss: 0.8837 - val_mae: 0.6645 - val_rmse: 0.9400 - val_mse: 0.8837\n",
      "Epoch 68/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8426 - mae: 0.6509 - rmse: 0.9179 - mse: 0.8426\n",
      "Epoch 68: saving model to models\\postDecomp_multivar_epoch_68.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8424 - mae: 0.6509 - rmse: 0.9178 - mse: 0.8424 - val_loss: 0.8850 - val_mae: 0.6595 - val_rmse: 0.9408 - val_mse: 0.8850\n",
      "Epoch 69/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8421 - mae: 0.6508 - rmse: 0.9176 - mse: 0.8421\n",
      "Epoch 69: saving model to models\\postDecomp_multivar_epoch_69.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8424 - mae: 0.6509 - rmse: 0.9178 - mse: 0.8424 - val_loss: 0.8840 - val_mae: 0.6700 - val_rmse: 0.9402 - val_mse: 0.8840\n",
      "Epoch 70/100\n",
      "4539/4539 [==============================] - ETA: 0s - loss: 0.8423 - mae: 0.6509 - rmse: 0.9178 - mse: 0.8423\n",
      "Epoch 70: saving model to models\\postDecomp_multivar_epoch_70.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8423 - mae: 0.6509 - rmse: 0.9178 - mse: 0.8423 - val_loss: 0.8823 - val_mae: 0.6677 - val_rmse: 0.9393 - val_mse: 0.8823\n",
      "Epoch 71/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8410 - mae: 0.6503 - rmse: 0.9171 - mse: 0.8410\n",
      "Epoch 71: saving model to models\\postDecomp_multivar_epoch_71.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8409 - mae: 0.6502 - rmse: 0.9170 - mse: 0.8409 - val_loss: 0.8816 - val_mae: 0.6557 - val_rmse: 0.9390 - val_mse: 0.8816\n",
      "Epoch 72/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8409 - mae: 0.6502 - rmse: 0.9170 - mse: 0.8409\n",
      "Epoch 72: saving model to models\\postDecomp_multivar_epoch_72.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8408 - mae: 0.6502 - rmse: 0.9169 - mse: 0.8408 - val_loss: 0.8839 - val_mae: 0.6574 - val_rmse: 0.9402 - val_mse: 0.8839\n",
      "Epoch 73/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8421 - mae: 0.6509 - rmse: 0.9177 - mse: 0.8421\n",
      "Epoch 73: saving model to models\\postDecomp_multivar_epoch_73.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8422 - mae: 0.6509 - rmse: 0.9177 - mse: 0.8422 - val_loss: 0.8828 - val_mae: 0.6618 - val_rmse: 0.9396 - val_mse: 0.8828\n",
      "Epoch 74/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8429 - mae: 0.6514 - rmse: 0.9181 - mse: 0.8429\n",
      "Epoch 74: saving model to models\\postDecomp_multivar_epoch_74.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8429 - mae: 0.6514 - rmse: 0.9181 - mse: 0.8429 - val_loss: 0.8856 - val_mae: 0.6533 - val_rmse: 0.9411 - val_mse: 0.8856\n",
      "Epoch 75/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8428 - mae: 0.6510 - rmse: 0.9180 - mse: 0.8428\n",
      "Epoch 75: saving model to models\\postDecomp_multivar_epoch_75.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8429 - mae: 0.6510 - rmse: 0.9181 - mse: 0.8429 - val_loss: 0.8827 - val_mae: 0.6609 - val_rmse: 0.9395 - val_mse: 0.8827\n",
      "Epoch 76/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8428 - mae: 0.6512 - rmse: 0.9181 - mse: 0.8428\n",
      "Epoch 76: saving model to models\\postDecomp_multivar_epoch_76.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8428 - mae: 0.6512 - rmse: 0.9181 - mse: 0.8428 - val_loss: 0.8821 - val_mae: 0.6559 - val_rmse: 0.9392 - val_mse: 0.8821\n",
      "Epoch 77/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8413 - mae: 0.6505 - rmse: 0.9172 - mse: 0.8413\n",
      "Epoch 77: saving model to models\\postDecomp_multivar_epoch_77.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8413 - mae: 0.6505 - rmse: 0.9172 - mse: 0.8413 - val_loss: 0.8823 - val_mae: 0.6535 - val_rmse: 0.9393 - val_mse: 0.8823\n",
      "Epoch 78/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8434 - mae: 0.6517 - rmse: 0.9184 - mse: 0.8434\n",
      "Epoch 78: saving model to models\\postDecomp_multivar_epoch_78.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8434 - mae: 0.6517 - rmse: 0.9184 - mse: 0.8434 - val_loss: 0.8836 - val_mae: 0.6603 - val_rmse: 0.9400 - val_mse: 0.8836\n",
      "Epoch 79/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8475 - mae: 0.6538 - rmse: 0.9206 - mse: 0.8475\n",
      "Epoch 79: saving model to models\\postDecomp_multivar_epoch_79.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8475 - mae: 0.6538 - rmse: 0.9206 - mse: 0.8475 - val_loss: 0.8908 - val_mae: 0.6672 - val_rmse: 0.9438 - val_mse: 0.8908\n",
      "Epoch 80/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8519 - mae: 0.6565 - rmse: 0.9230 - mse: 0.8519\n",
      "Epoch 80: saving model to models\\postDecomp_multivar_epoch_80.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8518 - mae: 0.6565 - rmse: 0.9229 - mse: 0.8518 - val_loss: 0.8944 - val_mae: 0.6622 - val_rmse: 0.9457 - val_mse: 0.8944\n",
      "Epoch 81/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8516 - mae: 0.6562 - rmse: 0.9228 - mse: 0.8516\n",
      "Epoch 81: saving model to models\\postDecomp_multivar_epoch_81.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8515 - mae: 0.6562 - rmse: 0.9227 - mse: 0.8515 - val_loss: 0.8939 - val_mae: 0.6620 - val_rmse: 0.9454 - val_mse: 0.8939\n",
      "Epoch 82/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8494 - mae: 0.6552 - rmse: 0.9216 - mse: 0.8494\n",
      "Epoch 82: saving model to models\\postDecomp_multivar_epoch_82.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8493 - mae: 0.6552 - rmse: 0.9216 - mse: 0.8493 - val_loss: 0.8900 - val_mae: 0.6663 - val_rmse: 0.9434 - val_mse: 0.8900\n",
      "Epoch 83/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8492 - mae: 0.6549 - rmse: 0.9215 - mse: 0.8492\n",
      "Epoch 83: saving model to models\\postDecomp_multivar_epoch_83.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8491 - mae: 0.6548 - rmse: 0.9215 - mse: 0.8491 - val_loss: 0.8900 - val_mae: 0.6607 - val_rmse: 0.9434 - val_mse: 0.8900\n",
      "Epoch 84/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8498 - mae: 0.6552 - rmse: 0.9219 - mse: 0.8498\n",
      "Epoch 84: saving model to models\\postDecomp_multivar_epoch_84.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8498 - mae: 0.6552 - rmse: 0.9219 - mse: 0.8498 - val_loss: 0.8928 - val_mae: 0.6599 - val_rmse: 0.9449 - val_mse: 0.8928\n",
      "Epoch 85/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8489 - mae: 0.6545 - rmse: 0.9214 - mse: 0.8489\n",
      "Epoch 85: saving model to models\\postDecomp_multivar_epoch_85.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8489 - mae: 0.6545 - rmse: 0.9214 - mse: 0.8489 - val_loss: 0.8893 - val_mae: 0.6702 - val_rmse: 0.9430 - val_mse: 0.8893\n",
      "Epoch 86/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8450 - mae: 0.6521 - rmse: 0.9192 - mse: 0.8450\n",
      "Epoch 86: saving model to models\\postDecomp_multivar_epoch_86.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8450 - mae: 0.6521 - rmse: 0.9192 - mse: 0.8450 - val_loss: 0.8820 - val_mae: 0.6570 - val_rmse: 0.9392 - val_mse: 0.8820\n",
      "Epoch 87/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8410 - mae: 0.6502 - rmse: 0.9171 - mse: 0.8410\n",
      "Epoch 87: saving model to models\\postDecomp_multivar_epoch_87.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8410 - mae: 0.6502 - rmse: 0.9170 - mse: 0.8410 - val_loss: 0.8810 - val_mae: 0.6574 - val_rmse: 0.9386 - val_mse: 0.8810\n",
      "Epoch 88/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8433 - mae: 0.6518 - rmse: 0.9183 - mse: 0.8433\n",
      "Epoch 88: saving model to models\\postDecomp_multivar_epoch_88.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8433 - mae: 0.6518 - rmse: 0.9183 - mse: 0.8433 - val_loss: 0.8879 - val_mae: 0.6595 - val_rmse: 0.9423 - val_mse: 0.8879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8441 - mae: 0.6522 - rmse: 0.9187 - mse: 0.8441\n",
      "Epoch 89: saving model to models\\postDecomp_multivar_epoch_89.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8441 - mae: 0.6522 - rmse: 0.9188 - mse: 0.8441 - val_loss: 0.8856 - val_mae: 0.6569 - val_rmse: 0.9411 - val_mse: 0.8856\n",
      "Epoch 90/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8444 - mae: 0.6522 - rmse: 0.9189 - mse: 0.8444\n",
      "Epoch 90: saving model to models\\postDecomp_multivar_epoch_90.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8444 - mae: 0.6522 - rmse: 0.9189 - mse: 0.8444 - val_loss: 0.8852 - val_mae: 0.6639 - val_rmse: 0.9408 - val_mse: 0.8852\n",
      "Epoch 91/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8448 - mae: 0.6522 - rmse: 0.9191 - mse: 0.8448\n",
      "Epoch 91: saving model to models\\postDecomp_multivar_epoch_91.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8449 - mae: 0.6522 - rmse: 0.9192 - mse: 0.8449 - val_loss: 0.8917 - val_mae: 0.6541 - val_rmse: 0.9443 - val_mse: 0.8917\n",
      "Epoch 92/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8483 - mae: 0.6545 - rmse: 0.9211 - mse: 0.8483\n",
      "Epoch 92: saving model to models\\postDecomp_multivar_epoch_92.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8482 - mae: 0.6545 - rmse: 0.9210 - mse: 0.8482 - val_loss: 0.8883 - val_mae: 0.6629 - val_rmse: 0.9425 - val_mse: 0.8883\n",
      "Epoch 93/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8478 - mae: 0.6539 - rmse: 0.9208 - mse: 0.8478\n",
      "Epoch 93: saving model to models\\postDecomp_multivar_epoch_93.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8478 - mae: 0.6539 - rmse: 0.9208 - mse: 0.8478 - val_loss: 0.8908 - val_mae: 0.6655 - val_rmse: 0.9438 - val_mse: 0.8908\n",
      "Epoch 94/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8480 - mae: 0.6541 - rmse: 0.9209 - mse: 0.8480\n",
      "Epoch 94: saving model to models\\postDecomp_multivar_epoch_94.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8479 - mae: 0.6541 - rmse: 0.9208 - mse: 0.8479 - val_loss: 0.8890 - val_mae: 0.6639 - val_rmse: 0.9429 - val_mse: 0.8890\n",
      "Epoch 95/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8473 - mae: 0.6536 - rmse: 0.9205 - mse: 0.8473\n",
      "Epoch 95: saving model to models\\postDecomp_multivar_epoch_95.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8474 - mae: 0.6536 - rmse: 0.9205 - mse: 0.8474 - val_loss: 0.8882 - val_mae: 0.6625 - val_rmse: 0.9425 - val_mse: 0.8882\n",
      "Epoch 96/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8449 - mae: 0.6523 - rmse: 0.9192 - mse: 0.8449\n",
      "Epoch 96: saving model to models\\postDecomp_multivar_epoch_96.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8449 - mae: 0.6523 - rmse: 0.9192 - mse: 0.8449 - val_loss: 0.8857 - val_mae: 0.6646 - val_rmse: 0.9411 - val_mse: 0.8857\n",
      "Epoch 97/100\n",
      "4538/4539 [============================>.] - ETA: 0s - loss: 0.8426 - mae: 0.6511 - rmse: 0.9179 - mse: 0.8426\n",
      "Epoch 97: saving model to models\\postDecomp_multivar_epoch_97.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8426 - mae: 0.6511 - rmse: 0.9179 - mse: 0.8426 - val_loss: 0.8849 - val_mae: 0.6639 - val_rmse: 0.9407 - val_mse: 0.8849\n",
      "Epoch 98/100\n",
      "4536/4539 [============================>.] - ETA: 0s - loss: 0.8416 - mae: 0.6509 - rmse: 0.9174 - mse: 0.8416\n",
      "Epoch 98: saving model to models\\postDecomp_multivar_epoch_98.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8414 - mae: 0.6509 - rmse: 0.9173 - mse: 0.8414 - val_loss: 0.8840 - val_mae: 0.6649 - val_rmse: 0.9402 - val_mse: 0.8840\n",
      "Epoch 99/100\n",
      "4535/4539 [============================>.] - ETA: 0s - loss: 0.8426 - mae: 0.6511 - rmse: 0.9180 - mse: 0.8426\n",
      "Epoch 99: saving model to models\\postDecomp_multivar_epoch_99.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8425 - mae: 0.6510 - rmse: 0.9179 - mse: 0.8425 - val_loss: 0.8852 - val_mae: 0.6606 - val_rmse: 0.9409 - val_mse: 0.8852\n",
      "Epoch 100/100\n",
      "4537/4539 [============================>.] - ETA: 0s - loss: 0.8434 - mae: 0.6515 - rmse: 0.9184 - mse: 0.8434\n",
      "Epoch 100: saving model to models\\postDecomp_multivar_epoch_100.h5\n",
      "4539/4539 [==============================] - 64s 14ms/step - loss: 0.8433 - mae: 0.6515 - rmse: 0.9183 - mse: 0.8433 - val_loss: 0.8894 - val_mae: 0.6570 - val_rmse: 0.9431 - val_mse: 0.8894\n",
      "1514/1514 [==============================] - 6s 4ms/step - loss: 0.8713 - mae: 0.6556 - rmse: 0.9335 - mse: 0.8713\n",
      "Test RMSE = 0.93   |   MAE = 0.66\n"
     ]
    }
   ],
   "source": [
    "#  Create a checkpoint callback\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='models/postDecomp_multivar_epoch_{epoch:02d}.h5',\n",
    "    save_freq='epoch',                        # save after each epoch\n",
    "    save_weights_only=False,                  # save the entire model (architecture + weights + optimizer state)\n",
    "    verbose=1)\n",
    "\n",
    "history_after = model_after.fit(\n",
    "    ds_train_after,\n",
    "    epochs=100,\n",
    "    # Validation is used to determine if model is overfitting\n",
    "    validation_data=ds_val_after,\n",
    "    callbacks=[ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = model_after.evaluate(ds_test_after, return_dict=True)\n",
    "print(f\"Test RMSE = {results['rmse']:.2f}   |   MAE = {results['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2dba84e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPhIh3THUT5I",
    "outputId": "ba185ed0-e338-492d-db9f-c78820c321c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE  = 4022.36 (mg/dL)^2\n",
      "Test RMSE = 63.42 mg/dL\n",
      "Test MAE  = 44.11 mg/dL\n",
      "Test R^2  = -0.1221\n"
     ]
    }
   ],
   "source": [
    "y_pred_z = model_after.predict(ds_test_after, verbose=0).ravel()   # z-scores\n",
    "y_true_z = y_test_after\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred_after = y_pred_z * std_glu_after + mu_glu_after\n",
    "y_true_after = y_true_z * std_glu_after + mu_glu_after\n",
    "\n",
    "# metrics in true units\n",
    "mse  = np.mean((y_true - y_pred) ** 2)    \n",
    "rmse = np.sqrt(mse)\n",
    "mae  = np.mean(np.abs(y_true - y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Test MSE  = {mse :.2f} (mg/dL)^2\")\n",
    "print(f\"Test RMSE = {rmse:.2f} mg/dL\")\n",
    "print(f\"Test MAE  = {mae :.2f} mg/dL\")\n",
    "print(f\"Test R^2  = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefc397",
   "metadata": {},
   "source": [
    "# Post-Decompensation Classification Metrics\n",
    "\n",
    "Below we convert to classification metrics for the post-decompensation model so we can compare to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e973a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_after_z = model_after.predict(ds_test_after, verbose=0).ravel()   # z-scores\n",
    "y_true_after_z = y_test_after\n",
    "mu_glu_after, std_glu_after = SCALERS_AFTER[1]          # index 1 is BG scale values\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred_after = y_pred_after_z * std_glu_after + mu_glu_after\n",
    "y_true_after = y_true_after_z * std_glu_after + mu_glu_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92ceb56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = convert_categorical(y_pred_after)\n",
    "y_true_class = convert_categorical(y_true_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8b9d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_true_encoded = le.fit_transform(y_true_class)  # e.g. 'Hypo'=0, 'Normal'=1, 'Hyper'=2\n",
    "y_pred_encoded = le.transform(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9d81d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Hyper       0.43      0.01      0.01     19608\n",
      "        Hypo       1.00      0.00      0.00      1064\n",
      "      Normal       0.79      1.00      0.88     76191\n",
      "\n",
      "    accuracy                           0.79     96863\n",
      "   macro avg       0.74      0.33      0.30     96863\n",
      "weighted avg       0.72      0.79      0.69     96863\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  108     0 19500]\n",
      " [    2     1  1061]\n",
      " [  139     0 76052]]\n"
     ]
    }
   ],
   "source": [
    "# Full classification metrics\n",
    "print(classification_report(y_true_encoded, y_pred_encoded, target_names=le.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_encoded, y_pred_encoded)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f528a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-average AUC-ROC: 0.5014\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode\n",
    "y_true_bin = label_binarize(y_true_encoded, classes=[0,1,2])\n",
    "y_pred_bin = label_binarize(y_pred_encoded, classes=[0,1,2])\n",
    "\n",
    "# Macro-average AUC\n",
    "auc_macro = roc_auc_score(y_true_bin, y_pred_bin, average='macro', multi_class='ovo')\n",
    "print(f\"Macro-average AUC-ROC: {auc_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bab0ba",
   "metadata": {},
   "source": [
    "## Testing pre-decompensation and post-decompensation models as one system\n",
    "\n",
    "Below we test both pre-decompensation and post-decompensation models as if they were a conjoined system. So if a patient had a dysglycemic event previously, the post-decompensation model would be used. If no previous dysglycemic event occurred (in an ICU stay), then a pre-decompensation model would be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c04a1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-decompensation test results\n",
    "y_pred_before_z = model_before.predict(ds_test_before, verbose=0).ravel()   # z-scores\n",
    "y_true_before_z = y_test_before\n",
    "mu_glu_before, std_glu_before = SCALERS_BEFORE[1]          # index 1 is BG scale values\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred_before = y_pred_before_z * std_glu_before + mu_glu_before\n",
    "y_true_before = y_true_before_z * std_glu_before + mu_glu_before\n",
    "\n",
    "# Post-decompensation test results\n",
    "y_pred_after_z = model_after.predict(ds_test_after, verbose=0).ravel()   # z-scores\n",
    "y_true_after_z = y_test_after\n",
    "mu_glu_after, std_glu_after = SCALERS_AFTER[1]          # index 1 is BG scale values\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred_after = y_pred_after_z * std_glu_after + mu_glu_after\n",
    "y_true_after = y_true_after_z * std_glu_after + mu_glu_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950a17fe",
   "metadata": {},
   "source": [
    "Below we combine the results so we can run testing metrics on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22a7a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.hstack([y_pred_before, y_pred_after])\n",
    "y_true = np.hstack([y_true_before, y_true_after])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "482d6bb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE  = 3104.24 (mg/dL)^2\n",
      "Test RMSE = 55.72 mg/dL\n",
      "Test MAE  = 37.19 mg/dL\n",
      "Test R^2  = 0.0292\n"
     ]
    }
   ],
   "source": [
    "mse  = np.mean((y_true - y_pred) ** 2)    \n",
    "rmse = np.sqrt(mse)\n",
    "mae  = np.mean(np.abs(y_true - y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Test MSE  = {mse :.2f} (mg/dL)^2\")\n",
    "print(f\"Test RMSE = {rmse:.2f} mg/dL\")\n",
    "print(f\"Test MAE  = {mae :.2f} mg/dL\")\n",
    "print(f\"Test R^2  = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de694c8",
   "metadata": {},
   "source": [
    "#### Classification Metrics for combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8abf9ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Hyper       0.43      0.00      0.01     24747\n",
      "        Hypo       1.00      0.00      0.00      1424\n",
      "      Normal       0.82      1.00      0.90    116657\n",
      "\n",
      "    accuracy                           0.82    142828\n",
      "   macro avg       0.75      0.33      0.30    142828\n",
      "weighted avg       0.75      0.82      0.74    142828\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   110      0  24637]\n",
      " [     2      1   1421]\n",
      " [   144      0 116513]]\n",
      "\n",
      "Macro-average AUC-ROC: 0.5012\n"
     ]
    }
   ],
   "source": [
    "y_pred_class = convert_categorical(y_pred)\n",
    "y_true_class = convert_categorical(y_true)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_true_encoded = le.fit_transform(y_true_class)  # e.g. 'Hypo'=0, 'Normal'=1, 'Hyper'=2\n",
    "y_pred_encoded = le.transform(y_pred_class)\n",
    "\n",
    "# Full classification metrics\n",
    "print(classification_report(y_true_encoded, y_pred_encoded, target_names=le.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_encoded, y_pred_encoded)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# One-hot encode\n",
    "y_true_bin = label_binarize(y_true_encoded, classes=[0,1,2])\n",
    "y_pred_bin = label_binarize(y_pred_encoded, classes=[0,1,2])\n",
    "\n",
    "# Macro-average AUC\n",
    "auc_macro = roc_auc_score(y_true_bin, y_pred_bin, average='macro', multi_class='ovo')\n",
    "print(f\"\\nMacro-average AUC-ROC: {auc_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d07d11-f6ed-4597-9b1a-5278f7f5ca23",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855f9a3",
   "metadata": {},
   "source": [
    "Below we experiment with some hyperparameter tuning for the LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c32071b-3e96-406a-8b5a-d4a580b893a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Pickles/split_before_glu_train.pkl.gz'\n",
    "with gzip.open(train_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "X_train_gs = train_data['X_train']\n",
    "y_train_gs = train_data['y_train']\n",
    "SCALERS_GS  = train_data['scalers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c49d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_glu_gs, std_glu_gs = SCALERS_GS[GLU_IDX]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "944cccde-11f5-47b6-94fc-dc942fbe8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lstm_units=64, dense_units=32, learning_rate=0.001):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Masking(mask_value=SENTINEL, input_shape=(L, F)),\n",
    "        tf.keras.layers.LSTM(lstm_units),\n",
    "        tf.keras.layers.Dense(dense_units, activation='relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae', RootMeanSquaredError(name='rmse'), 'mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f0d750-39e1-4165-aa38-66d8dc755014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mashal\\AppData\\Local\\Temp\\ipykernel_27412\\725283007.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  reg = KerasRegressor(build_fn=build_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "reg = KerasRegressor(build_fn=build_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'lstm_units': [32, 64],\n",
    "    'dense_units': [16, 32],\n",
    "    'learning_rate': [0.001, 0.0001, 0.0005],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "976a5f80-9113-4a82-b6c7-8b8f6e4cc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=reg, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "grid_result = grid.fit(X_train_gs, y_train_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b089d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'dense_units': 32, 'learning_rate': 0.001, 'lstm_units': 64}\n",
      "Best RMSE (sqrt of neg-MSE): 35.992317032825504\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params:\", grid_result.best_params_)\n",
    "print(\"Best RMSE (sqrt of neg-MSE):\", (-grid_result.best_score_) ** 0.5 * std_glu_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "582956cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'lstm_units': [128, 256],\n",
    "    'dense_units': [32, 64, 128],\n",
    "    'learning_rate': [0.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c731531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2 = GridSearchCV(estimator=reg, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
    "grid_result2 = grid2.fit(X_train_gs, y_train_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fa6e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'dense_units': 32, 'learning_rate': 0.001, 'lstm_units': 256}\n",
      "Best RMSE (sqrt of neg-MSE): 35.97127904800289\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Params:\", grid_result2.best_params_)\n",
    "print(\"Best RMSE (sqrt of neg-MSE):\", (-grid_result2.best_score_) ** 0.5 * std_glu_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d39b0ce-d392-422d-acdd-e845e12ba953",
   "metadata": {},
   "source": [
    "### Below we test the best gridsearch model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caf2c13b-d448-4985-8554-6f7d46276a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gs = build_model(256, 32, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbcb67fb-01ae-43ef-8ec2-bf16ddb2dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'Pickles/filtered_glu_test.pkl.gz'\n",
    "with gzip.open(test_path, 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "X_test_gs = train_data['X_test']\n",
    "y_test_gs = train_data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561503b6-29cf-418f-9c51-25d233d575f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test_gs  = make_ds(X_test_gs,  y_test_gs,  shuffle=False)\n",
    "ds_train_gs  = make_ds(X_train_gs,  y_train_gs,  shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "532f26f1-2291-4b07-b9f8-3a4fcace04f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5062 - mae: 0.4597 - rmse: 0.7115 - mse: 0.5062     \n",
      "Epoch 1: saving model to models\\preDecomp_gs_epoch_01.h5\n",
      "2155/2155 [==============================] - 30s 13ms/step - loss: 0.5062 - mae: 0.4598 - rmse: 0.7115 - mse: 0.5062\n",
      "Epoch 2/10\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5033 - mae: 0.4579 - rmse: 0.7095 - mse: 0.5033 \n",
      "Epoch 2: saving model to models\\preDecomp_gs_epoch_02.h5\n",
      "2155/2155 [==============================] - 29s 13ms/step - loss: 0.5033 - mae: 0.4579 - rmse: 0.7095 - mse: 0.5033\n",
      "Epoch 3/10\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5030 - mae: 0.4573 - rmse: 0.7092 - mse: 0.5030 \n",
      "Epoch 3: saving model to models\\preDecomp_gs_epoch_03.h5\n",
      "2155/2155 [==============================] - 29s 13ms/step - loss: 0.5030 - mae: 0.4573 - rmse: 0.7092 - mse: 0.5030\n",
      "Epoch 4/10\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5020 - mae: 0.4564 - rmse: 0.7085 - mse: 0.5020 \n",
      "Epoch 4: saving model to models\\preDecomp_gs_epoch_04.h5\n",
      "2155/2155 [==============================] - 30s 14ms/step - loss: 0.5020 - mae: 0.4564 - rmse: 0.7085 - mse: 0.5020\n",
      "Epoch 5/10\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.5023 - mae: 0.4569 - rmse: 0.7088 - mse: 0.5023 \n",
      "Epoch 5: saving model to models\\preDecomp_gs_epoch_05.h5\n",
      "2155/2155 [==============================] - 30s 14ms/step - loss: 0.5024 - mae: 0.4570 - rmse: 0.7088 - mse: 0.5024\n",
      "Epoch 6/10\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5024 - mae: 0.4566 - rmse: 0.7088 - mse: 0.5024 \n",
      "Epoch 6: saving model to models\\preDecomp_gs_epoch_06.h5\n",
      "2155/2155 [==============================] - 29s 14ms/step - loss: 0.5024 - mae: 0.4566 - rmse: 0.7088 - mse: 0.5024\n",
      "Epoch 7/10\n",
      "2154/2155 [============================>.] - ETA: 0s - loss: 0.5019 - mae: 0.4567 - rmse: 0.7085 - mse: 0.5019 \n",
      "Epoch 7: saving model to models\\preDecomp_gs_epoch_07.h5\n",
      "2155/2155 [==============================] - 29s 13ms/step - loss: 0.5020 - mae: 0.4567 - rmse: 0.7085 - mse: 0.5020\n",
      "Epoch 8/10\n",
      "2152/2155 [============================>.] - ETA: 0s - loss: 0.5023 - mae: 0.4568 - rmse: 0.7087 - mse: 0.5023 \n",
      "Epoch 8: saving model to models\\preDecomp_gs_epoch_08.h5\n",
      "2155/2155 [==============================] - 31s 15ms/step - loss: 0.5023 - mae: 0.4569 - rmse: 0.7087 - mse: 0.5023\n",
      "Epoch 9/10\n",
      "2155/2155 [==============================] - ETA: 0s - loss: 0.5024 - mae: 0.4569 - rmse: 0.7088 - mse: 0.5024 \n",
      "Epoch 9: saving model to models\\preDecomp_gs_epoch_09.h5\n",
      "2155/2155 [==============================] - 31s 14ms/step - loss: 0.5024 - mae: 0.4569 - rmse: 0.7088 - mse: 0.5024\n",
      "Epoch 10/10\n",
      "2153/2155 [============================>.] - ETA: 0s - loss: 0.5029 - mae: 0.4572 - rmse: 0.7091 - mse: 0.5029 \n",
      "Epoch 10: saving model to models\\preDecomp_gs_epoch_10.h5\n",
      "2155/2155 [==============================] - 32s 15ms/step - loss: 0.5029 - mae: 0.4572 - rmse: 0.7091 - mse: 0.5029\n",
      "1325/1325 [==============================] - 8s 5ms/step - loss: 0.8725 - mae: 0.6081 - rmse: 0.9341 - mse: 0.8725\n",
      "Test RMSE = 0.93   |   MAE = 0.61\n"
     ]
    }
   ],
   "source": [
    "#  Create a checkpoint callback\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='models/preDecomp_gs_epoch_{epoch:02d}.h5',\n",
    "    save_freq='epoch',                        # save after each epoch\n",
    "    save_weights_only=False,                  # save the entire model (architecture + weights + optimizer state)\n",
    "    verbose=1)\n",
    "\n",
    "history_after = model_gs.fit(\n",
    "    ds_train_gs,\n",
    "    epochs=10,\n",
    "    callbacks=[ckpt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = model_gs.evaluate(ds_test_gs, return_dict=True)\n",
    "print(f\"Test RMSE = {results['rmse']:.2f}   |   MAE = {results['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74dcd214-ab00-4d24-8b86-410e7406612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE  = 2249.20 (mg/dL)^2\n",
      "Test RMSE = 47.43 mg/dL\n",
      "Test MAE  = 30.88 mg/dL\n",
      "Test R^2  = -0.0080\n"
     ]
    }
   ],
   "source": [
    "y_pred_z = model_gs.predict(ds_test_gs, verbose=0).ravel()   # z-scores\n",
    "y_true_z = y_test_gs\n",
    "\n",
    "mu_glu_gs, std_glu_gs = SCALERS_GS[1]          # index 1 is BG scale values\n",
    "\n",
    "# inverse-transform back to mg/dL\n",
    "y_pred_gs = y_pred_z * std_glu_gs + mu_glu_gs\n",
    "y_true_gs = y_true_z * std_glu_gs + mu_glu_gs\n",
    "\n",
    "# metrics in true units\n",
    "mse  = np.mean((y_true_gs - y_pred_gs) ** 2)    \n",
    "rmse = np.sqrt(mse)\n",
    "mae  = np.mean(np.abs(y_true_gs - y_pred_gs))\n",
    "r2 = r2_score(y_true_gs, y_pred_gs)\n",
    "\n",
    "print(f\"Test MSE  = {mse :.2f} (mg/dL)^2\")\n",
    "print(f\"Test RMSE = {rmse:.2f} mg/dL\")\n",
    "print(f\"Test MAE  = {mae :.2f} mg/dL\")\n",
    "print(f\"Test R^2  = {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
